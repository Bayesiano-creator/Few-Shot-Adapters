{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5287a8d",
   "metadata": {},
   "source": [
    "## Set Global Seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e68a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The global seed 260615\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed = 260615\n",
    "set_all_seeds(seed)\n",
    "\n",
    "print(\"The global seed \" + str(seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a407e6",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0faaf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANGUAGE\n",
    "\n",
    "_LANGUAGE_         = 'es'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f81690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL CLASSIFICATION\n",
    "\n",
    "_PRETRAINED_LM_    = 'pysentimiento/robertuito-base-uncased'\n",
    "_PREPROCESS_TEXT_  = True\n",
    "_TWEET_BATCH_SIZE_ = 5\n",
    "_ADAPTER_CONFIG_   = transformers.ParallelConfig(reduction_factor = 256)\n",
    "_MAX_SEQ_LEN_      = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daabdab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "\n",
    "_OUTPUT_DIR_       = 'checkPointsFE'\n",
    "_LOGGING_STEPS_    = 50\n",
    "_NUM_AUTHORS_      = 256\n",
    "_K_FOLD_CV_        = 5\n",
    "_NO_GPUS_          = 1\n",
    "_BATCH_SIZE_       = int(32 / _NO_GPUS_)\n",
    "_EPOCHS_           = 10\n",
    "_LEARNING_RATE_    = 1e-4\n",
    "\n",
    "# PREDICTIONS\n",
    "\n",
    "_DATASET_          = 'PAN17'\n",
    "_PRED_DIR_         = 'FE_5tweet'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2c9214",
   "metadata": {},
   "source": [
    "## Other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b722fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL DICTONARIES -----------------------------------------------------------------------\n",
    "\n",
    "gender_dict    = {'female': 0, 'male':   1}\n",
    "varietyEN_dict = {'australia': 0, 'canada': 1, 'great britain': 2, 'ireland': 3, 'new zealand': 4, 'united states': 5}\n",
    "varietyES_dict = {'argentina': 0, 'chile': 1, 'colombia': 2, 'mexico': 3, 'peru': 4, 'spain': 5, 'venezuela': 6}  \n",
    "\n",
    "genderEN_hip  = {0: 'I’m a female', 1: 'I’m a male'}\n",
    "genderES_hip  = {0: 'Mi nombre es María', 1: 'Mi nombre es José'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc921f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET LANGUAGE DICTIONARIES\n",
    "\n",
    "if _LANGUAGE_ == 'en':\n",
    "    gender_hip   = genderEN_hip\n",
    "    variety_dict = varietyEN_dict\n",
    "\n",
    "elif _LANGUAGE_ == 'es':\n",
    "    gender_hip   = genderES_hip\n",
    "    variety_dict = varietyES_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c35894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET LANGUAGE TOKENIZER\n",
    "\n",
    "from transformers import AutoTokenizer, PretrainedConfig\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(_PRETRAINED_LM_)\n",
    "vocab = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ef9838",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6438e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading data...\n",
      "    Done\n",
      "Preprocessing text...\n",
      "    Done\n",
      "Tokenizing...\n",
      "    Done\n",
      "Merging data...\n",
      "    Done\n",
      "\n",
      "Total Instances: 419998\n",
      "\n",
      "\n",
      "Reading data...\n",
      "    Done\n",
      "Preprocessing text...\n",
      "    Done\n",
      "Tokenizing...\n",
      "    Done\n",
      "Merging data...\n",
      "    Done\n",
      "\n",
      "Total Instances: 280000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tools.DataLoaders import BasePAN17\n",
    "\n",
    "baseTrain  = BasePAN17(Dir             = 'data/2017',\n",
    "                      split            = 'train',\n",
    "                      language         = _LANGUAGE_,\n",
    "                      tokenizer        = tokenizer,\n",
    "                      gender_dict      = gender_dict,\n",
    "                      variety_dict     = variety_dict,\n",
    "                      tweet_batch_size = 1,\n",
    "                      max_seq_len      = _MAX_SEQ_LEN_,\n",
    "                      preprocess_text  = _PREPROCESS_TEXT_)\n",
    "\n",
    "baseTest  = BasePAN17(Dir              = 'data/2017',\n",
    "                      split            = 'test',\n",
    "                      language         = _LANGUAGE_,\n",
    "                      tokenizer        = tokenizer,\n",
    "                      gender_dict      = gender_dict,\n",
    "                      variety_dict     = variety_dict,\n",
    "                      tweet_batch_size = 1,\n",
    "                      max_seq_len      = _MAX_SEQ_LEN_,\n",
    "                      preprocess_text  = _PREPROCESS_TEXT_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a6a42ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossVal_splits = []\n",
    "\n",
    "for val_idx in range(_K_FOLD_CV_):\n",
    "    \n",
    "    authors_train, authors_val = baseTrain.cross_val(_K_FOLD_CV_, val_idx, _NUM_AUTHORS_)\n",
    "    \n",
    "    crossVal_splits.append( (authors_train, authors_val) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad88695d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading data...\n",
      "    Done\n",
      "Preprocessing text...\n",
      "    Done\n",
      "Tokenizing...\n",
      "    Done\n",
      "Merging data...\n",
      "    Done\n",
      "\n",
      "Total Instances: 84000\n",
      "\n",
      "\n",
      "Reading data...\n",
      "    Done\n",
      "Preprocessing text...\n",
      "    Done\n",
      "Tokenizing...\n",
      "    Done\n",
      "Merging data...\n",
      "    Done\n",
      "\n",
      "Total Instances: 56000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tools.DataLoaders import BasePAN17\n",
    "\n",
    "baseTrain  = BasePAN17(Dir             = 'data/2017',\n",
    "                      split            = 'train',\n",
    "                      language         = _LANGUAGE_,\n",
    "                      tokenizer        = tokenizer,\n",
    "                      gender_dict      = gender_dict,\n",
    "                      variety_dict     = variety_dict,\n",
    "                      tweet_batch_size = _TWEET_BATCH_SIZE_,\n",
    "                      max_seq_len      = _MAX_SEQ_LEN_,\n",
    "                      preprocess_text  = _PREPROCESS_TEXT_)\n",
    "\n",
    "baseTest  = BasePAN17(Dir              = 'data/2017',\n",
    "                      split            = 'test',\n",
    "                      language         = _LANGUAGE_,\n",
    "                      tokenizer        = tokenizer,\n",
    "                      gender_dict      = gender_dict,\n",
    "                      variety_dict     = variety_dict,\n",
    "                      tweet_batch_size = _TWEET_BATCH_SIZE_,\n",
    "                      max_seq_len      = _MAX_SEQ_LEN_,\n",
    "                      preprocess_text  = _PREPROCESS_TEXT_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae2a37e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.DataLoaders import DatasetPAN17\n",
    "\n",
    "Test = DatasetPAN17(baseTest, 'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49820915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bafc7670beae172539e66c48858d8a',\n",
       " '70250236e5aae9df16d3d081b24f8c52',\n",
       " '4230dfe217cc7d667e6a21bff301263d',\n",
       " 'b1be8bd39d7a3be53d2e37a654db05d8',\n",
       " '8690c40c4fea5fdb6ad1c030cafca7f',\n",
       " 'eb3d30f6a613d63c495faf276ce8af20',\n",
       " 'aeef24da173bad8c8589593068d12e2b',\n",
       " '3fccf54ed8ff8ebf3e09b27178c3eda6',\n",
       " '5341c6e38c6ff6d6a3dc11eac05a08de',\n",
       " 'f8707cb24018d27812ad57586e45bf4e',\n",
       " '351e949f234bd6223b9921b3522a90ce',\n",
       " 'bd2c8464416d5a45cffc1a6ae7db12de',\n",
       " '2e5946874ebd8880ac4356c5491d5f85',\n",
       " '78c318d74686fee6dea0f10d0fd805f2',\n",
       " 'cd30f8d42568f41737f63b7fe3d74206',\n",
       " '1fb9ec36c0d6afecb0bcdd74dc1140c8',\n",
       " '10880d19d7346373a42b18e505bbc4d5',\n",
       " '534bfd160e0b7a8659e5854dc8deb795',\n",
       " '32d2ef7c31d22593e24a9cc59c00698c',\n",
       " '35aa53616736e99b24d0190b114873ab',\n",
       " '6c085614b68ce2c31216b4ca45b50131',\n",
       " '7c830bd1093b26c192cb0b307303803a',\n",
       " '4f3d4bd16d919fdab790f073bc71fefc',\n",
       " 'de9f0a8cf6ec53f7d0e907b19d92fcab',\n",
       " '4ffefe7a85e2acecfe321208aab3c7ca',\n",
       " 'b90c6c58d2dd8602765bad6df8c4a732',\n",
       " '5e7290bad2b0f904247e9e7583010a7d',\n",
       " 'a25294da8989df8a3d698597dc1337b2',\n",
       " '93a9ee764e4fa31fc2157075811e56d7',\n",
       " '6f09f381da6c49fa677637028441046f',\n",
       " '37b59f11ad1071307017c060bb2770f8',\n",
       " '3a341476495755450344dc2e8937db74',\n",
       " 'e781f9c7a6a0e856effca2c26da173cd',\n",
       " '218e06b0e4c640a4884813efd51214f9',\n",
       " '2b0deda35c16864b466df4fc25661278',\n",
       " '8c092bdcb91a1d4560e3b360ca107806',\n",
       " 'a16ac4fbe7a306298927244819e920a9',\n",
       " '990062e1011b693b0324928b00fc763e',\n",
       " '1ed4440b5bc2800b86533e09fec03c9f',\n",
       " '759dda19a6e2f2158b0e95b0a82ae40d',\n",
       " '786c626d5462bc7f4d76045e170aca1b',\n",
       " 'e54d1776fda5d4956c046c64dc5c2a32',\n",
       " '8ad696c62430f4b4df3a639353041434',\n",
       " 'e96161063109e33edd1ff890014a2ed3',\n",
       " '4395b412b13d6212654cd859655ea3',\n",
       " 'b414636b471de8b1b17932ee9df0688e',\n",
       " '6e4ef72ffa6249ae564b58837ecaa01b',\n",
       " '8d9de1fde3f7c4653f0c8ca7883e9d36',\n",
       " '2cd34c7b9d8fbab6edd8673c7c60b0d2',\n",
       " 'f37dc1d42d83897993e541e68c10c72',\n",
       " 'f96bcf0cfd9d9ff3ee882f64d537c6ae',\n",
       " '35d9521c4faa75418ad0552f2280c956',\n",
       " '40cb831b684e6bf6c84287fd9dac19d0',\n",
       " 'c3dadaeffb5280e5b2036d655688b21c',\n",
       " 'ff71a74eace072801ba76b84db05da34',\n",
       " 'a8b55605c56eb65189201cb16f1b66d2',\n",
       " 'a9016628029128a78b930d4d27f14a09',\n",
       " 'f6beb6154a75362e77418da262a205c4',\n",
       " '31485a4e5b5a5ce1febd99a7480d9ca4',\n",
       " 'fa472cd3e5d94ada0eb61f9e75b45b0e',\n",
       " '6625bb8da76c870f22d7b66f8cbdeb93',\n",
       " '6e8ef9177f571e6877b44f3268eca219',\n",
       " '7e0221007e71c17169c304d8fa7d5f37',\n",
       " 'aa5fc93fc57b78578f09f7558945bb22',\n",
       " 'dee946f916fe86f76e44b6a28a28da6b',\n",
       " '9b4cdcc2dee64548f3a9332cf4af0ad9',\n",
       " '4f0cc7351a05d147b9e1bbaa274c8c2c',\n",
       " '17b55d58f830c5a776f7d93c21aabc71',\n",
       " '18acf0867871fa5ba908a2f83e4a443',\n",
       " '422a9ea50ebb8e056556fcca4c5a4061',\n",
       " '8739943c4f90b5ec70fe0c665b2fe17',\n",
       " '97a77780c6b997d17e7423abab604d4',\n",
       " 'a42d41f01947c1c957fe6bf5770abcfb',\n",
       " 'e50e5d479894cb66d8f12cd1a64bba2e',\n",
       " '2b4457c98edc6b61e6985a169d7a993b',\n",
       " 'af8073434774b9e1d5b47d9fc8b1f812',\n",
       " 'b7a4e1d185f513869ba9dd7b4031f8b0',\n",
       " 'aba29b16cfa4b91155e9eafc2dcd980b',\n",
       " 'b1e5c3351cfa444eef65ed8e9c4e8892',\n",
       " 'ac3b4680075b9eda462d65264679c275',\n",
       " 'c993cc9c96c3df074358d49a6900104b',\n",
       " 'e4a7faffd07bc47cf9bec3fa803fc4e4',\n",
       " '9c91b36a381ee35f67ae4cbada9d2fca',\n",
       " 'd72bf0f41a1c1aa413ea7325a8dfee41',\n",
       " 'b06932f4e940fb4a8da35acce4f044c',\n",
       " 'c6513c42c41b98a21332b8558a6d0358',\n",
       " '9d6e31324ffd6b524ab970704556bd79',\n",
       " '412fc08dd79e5a2d6e4cff7dea8baf1a',\n",
       " '745e706da40a50cc9625d3bd548d4901',\n",
       " '1417150f4801a78d334426addb6465c2',\n",
       " '15fae2f0e671fdea5705e19484f23263',\n",
       " '606946349f9c239b797c06daf81ec1fc',\n",
       " '58320498c6fac3105605a5678ff03303',\n",
       " 'fdba31c033c0c3a744f0e453c7e5e475',\n",
       " 'e937b0d36525b294828e203c017ed824',\n",
       " 'cb93eafcc5e2c401e9d7a64ad6026c4c',\n",
       " 'a13c801761b823d3bbf1a06ecc3084c6',\n",
       " 'de8bd3df85b4366797361d5917fa80a7',\n",
       " '6d65795d3b0396a1e8abeed8f9a8a91c',\n",
       " '569442151d0530ca0fe86d0e1ea88723',\n",
       " '122b417a2ebe2a67d654be9420e7611',\n",
       " '168251add91b2b643ab6101229cb681',\n",
       " '31e9c1a42393733774c527042f3c22f7',\n",
       " 'fadbd22af85d045b9f6dac95d19cdfbc',\n",
       " '66d35492d6dab1a9ec68daa36f2f2dc9',\n",
       " 'a083fb2d9f02538f211d2a6598c3b56',\n",
       " 'ff4129328f1bf051e3e9f694414afe8f',\n",
       " '662c74d078d6aa320a8c13df5a83b533',\n",
       " 'e93a9c3ff5c28ac8ab6f09b647f7361c',\n",
       " 'dc4faa866ec5cdadc8ac93b913e71f1b',\n",
       " '75b0758783d6fb38f675aee83186aa69',\n",
       " 'a91804bdc9b34557f31bd5bad1ed32ed',\n",
       " 'da71f6e3c737ba9ce53d3318457ef4df',\n",
       " '56736457cedfb4fd33ec1a6c5b0e857',\n",
       " '4002ed2faff8efd3d59b40b8d76bd7c',\n",
       " 'cea9ce9db1fe263d178c9cee69a117f0',\n",
       " '8978d8d3ef4d21eec30cddefa36b773a',\n",
       " '347f0b7bb675e424c9730be07257132c',\n",
       " '44ee0151494830b00f692ad1e2accc7e',\n",
       " 'e680d8d04394c9d6be6b81a78f7f7ce1',\n",
       " 'e441a7a41997b3277a89f612acd019a0',\n",
       " '72c417c61bd623a27778f9ac664c96b0',\n",
       " 'a04b3432a862acc9bbf07e39943d0684',\n",
       " 'c97e31324a8785149b141e4df259152a',\n",
       " 'ca751bd2305bd60203a95c0d923ba78d',\n",
       " '85f3b683bb39b3a455d795c34826e3dd',\n",
       " 'be88af37e5d0a90439b9e0430eca3984',\n",
       " 'f6df81f2a96695db0b6399680521270c',\n",
       " '510ed3b6e098224cb49b6249ed158733',\n",
       " '92ffa98bade702b86417b118e8aca319',\n",
       " 'e84cb941c93353e76345fe559381dc31',\n",
       " 'f22d3da516d0d4b5c4a2d3b85d94368f',\n",
       " '19c039f2fd398bcccdadcc14db27125a',\n",
       " 'e72c150c5f3baac62996b14714524e77',\n",
       " '146f933997c8f761aafc362e84657a81',\n",
       " 'f548e69bbc165c39e5103cf5cb3e9095',\n",
       " '5ae03f4d9c3e48fc5bad148eb6ced049',\n",
       " 'c005d31d73fb1cac102effe6a32bbbfe',\n",
       " 'b2741743cae69fbe22bc8f14453b9a2c',\n",
       " '7cb1069a0331ccd5dc6c33113e0688d7',\n",
       " '8a4504e34441955d18a4c8dc73a5cd4b',\n",
       " 'ffc9c0b137c5bbb3f9173e7af991e122',\n",
       " '5d95e85a1fa9578b9560fdda7469b72',\n",
       " '4c717a9727a761e32e71fe7891b3f739',\n",
       " 'bdc850789f64354aaaa4935117e474f',\n",
       " 'a5f5ff32d2ae33aab6192077097f071e',\n",
       " 'c248ad36d046bad50f4fa1e67b00f164',\n",
       " '120f039af8b54288d629aa72f9ffe2c6',\n",
       " '132c59d82f054c03f867e2d98533bd0a',\n",
       " 'd4c3855c7c1111c1b8d303f911fb397c',\n",
       " 'd13deeef4e8fd6ac8eee98fc2366a7da',\n",
       " '73de7fb176f5557fd54a3c5b335cbe00',\n",
       " '4976a792d72503e14422174d4f96c471',\n",
       " 'c10e4513bbc5fac318d7862068e02e4a',\n",
       " 'ad103de83e40afb213067cb491ee2c97',\n",
       " '3d491029cf11929533f6028b8e47bd7a',\n",
       " 'd4c40c73965ffeea19bbedd66ce54a6e',\n",
       " 'e2bdc2c37a8a6fa7cbef7bd0949e6692',\n",
       " 'c85c2110302c568264297a56787afb11',\n",
       " '7d691ae1bdf82ea98e9994c9b040d74c',\n",
       " '21898041fd29473e7c23c0731b0c93a8',\n",
       " 'cef6fdb08f15700913352a8fe5af5353',\n",
       " '321f584d96f7d2d7ea4cd97d12db1fb8',\n",
       " '384abd84b92022d993ce0e42ed9a3b6b',\n",
       " '89bf0e277189d6248b53981aa3f8fec1',\n",
       " '94fbdfc8fc61383d9555c27fd75de661',\n",
       " '98868c2a592f6e6aab0f263fc3457645',\n",
       " 'f19ac0a9cc3ece1dac24db2cbff858db',\n",
       " '5a4e0474205125dc9067875161b0971a',\n",
       " 'cd04e3990c21beff0a273f9df7212cd3',\n",
       " '4fece4290fb9b25aec32ce50b0b54f',\n",
       " 'bf5c676924fb038c70702bd05c22cb6d',\n",
       " '8e65dda2b4f4c69db22e88bcd034af58',\n",
       " '3c379ef51acc19b0d097a43594913b72',\n",
       " '4fa0f263589b100e0b3f4b005d2ece8f',\n",
       " '74a891de64fb26b1fe32176167f6aa59',\n",
       " 'd0ff5d3e35193bc9b05800e4a752819e',\n",
       " '90d240a3562fe52fa48a15eb55fb668',\n",
       " 'dde2853f519a8b36d5fe2785efc804aa',\n",
       " '5aad5fa8f0c78f0520cad7820aaec43a',\n",
       " '9b88fdc095911d1e44346ba21bb6210d',\n",
       " '2a57fbec3d0309a5fed34dbd69387c31',\n",
       " '366b3608df0472f76c75c11d3f7ef126',\n",
       " 'e1a7a314e453c442fee05183ef495179',\n",
       " '9e1ecd2668a7f431d2492e15ce6679c0',\n",
       " 'cdd74fec658e07a72c0a23179f8c7968',\n",
       " '66ca6b8859183697127d125e05500d4',\n",
       " '29aedbb0deb8618a7b6fa309eb950595',\n",
       " '10bb37101c79cab0cc07b69d4fb67707',\n",
       " '2012b9ee88fe8f331939d25b86386cd7',\n",
       " '3fc6c7cc5e7652759a2f6e45f4add54c',\n",
       " 'e19babac853bf16d9a77360cdd297c60',\n",
       " 'f6a7578b44a1c79e2e88373113725166',\n",
       " '398ce248f02655ef9d5b9f4450aab928',\n",
       " '617bd501721737e4a9740b0d335e3bd5',\n",
       " '8da3552c9f5ce3dcc6323cc80bf68c7c',\n",
       " '4ff8e28432ab9cf2c6125f016bea94d7',\n",
       " '9bfa0d97bd0b7cb1e4d7b87ad4f6ff26',\n",
       " 'bb599a1233bff71f6426782d9c9adfce',\n",
       " 'dfb1c588997bf0fb647457f4486beb2',\n",
       " 'f97d53dc2398c364543ebb4dfce7099e',\n",
       " '4dae9e4e6eb405973ad31e0729d2059b',\n",
       " '3b814b3f963179118795c0b584875926',\n",
       " '65c1ff31131a198b2a8a0794c625760e',\n",
       " 'ff2aff26cb430d9463a977f34d1f2587',\n",
       " 'eeadc5a7fa48a7de0ad3b6cab012dae8',\n",
       " '5cde64c2d11d4b891b062c79fdf820a8',\n",
       " 'd7a3dfdab5f66e23c4bd024eb8173e0',\n",
       " '359007685e27ca6bac1ada852b63bd3a',\n",
       " 'bab54048b48462a7df793b73ec0705e1',\n",
       " 'a55f7c8283b14be7d8aeb5e8dac42892',\n",
       " '7c3c8a6a33a9e0f55cc7fe0dcd42fc9b',\n",
       " '54307d2a8618e83c3a9ebd4eea584f72',\n",
       " '1868968c5e99153299ec41b40ec2b749',\n",
       " '79a6dc76a962266ce0820db64b802cdc',\n",
       " 'b7bf672abb9a5e28173724a7484bf1b3',\n",
       " 'bfba942607eaab9962dc12bb6e8512c2',\n",
       " '7e5abe6eb16bd4cfccfcd193e202ac38',\n",
       " 'e745ba18f4b4506a3f06611092dcbb97',\n",
       " '838a4af6f1e40a620036f657c4caa637',\n",
       " '3d6db268fd7ccd755b1f4eadc4af61d6',\n",
       " 'a0480fa72479dae2c9cac4b57445a8bb',\n",
       " 'da15b311ead071b97a5f701bbac95056',\n",
       " '325877cdb0a7debc351348d1dd2e4fa9',\n",
       " 'bcc6fb1d76f5d15ed5418a86c546ccb1',\n",
       " 'b08133dd197ca2673544e12c984ad446',\n",
       " '833bf7d05e60c79f927c3688c90c79d6',\n",
       " '3b28c4da97782c4467b38093c439878c',\n",
       " '2f12fc6ba6d55e8ce0adf2a763c41d33',\n",
       " 'bdd6b2b1520c557bcc8bd107d0f3ded4',\n",
       " 'b0ce6e08f2ca6705cdec7e6c9d169b71',\n",
       " 'ae1f915b471933b0f92ef40db2c43482',\n",
       " 'c6db2246ee9c570e405ed4c2ee3598a1',\n",
       " '8187d1b96d1b585a40a177a2a505a918',\n",
       " '3e9c3dcab36f2d1d7cfe852b0b959d5a',\n",
       " 'e881852038b7a8767400517c9729d315',\n",
       " 'b370d3a05025fc7a619bc71d4b236ab8',\n",
       " '21bb49fa048c5f8adb5dc52b94468706',\n",
       " '252cbe90e22bb4a3c5678c57cf690afa',\n",
       " '6f9ce96c0a6df47b7361b53997e61e4d',\n",
       " 'a585c6418fda6e9744c40079251ff877',\n",
       " 'ab403bb324d467b192a04de401ccb4a9',\n",
       " '3245d75778371af6ebb8ba63465cb570',\n",
       " 'c923707f3f6068b0441657427455510a',\n",
       " '70b1c51c1349c83caecde22dad33e777',\n",
       " '38b5a681a5bd0ab44689b73459f249fe',\n",
       " '513f4ef46bdcf52001023ba0610abb17',\n",
       " 'e1135acced761f97dc725b4144c6c1e1',\n",
       " '3fb261b1333b5bf09101299bd00e4dc1',\n",
       " '1b1c38c3137392070ce9cf453aafb835',\n",
       " '63de148ab265f2901a32b50c7e977dfe',\n",
       " 'e92a9efc2fdbb6381f481f3f702e996',\n",
       " 'e0c77ed7e48dc8e5a63a7a8cb3ec07bc',\n",
       " 'b1f96a3ca0484f80cc2e633bd5a90de1',\n",
       " '36a69681a3759b029efed1b391017bbe',\n",
       " 'f5e38110de38166b856d212b8edc6177',\n",
       " '342fff6a57b6715161c6e4cb1567e978',\n",
       " '9da3a0ab8831cc825e7f72366b9ab6d6',\n",
       " '2a04a9034b4f36de93d6a676d2645859',\n",
       " '222a7209a1024b9a0da516d686751e2b',\n",
       " 'cb2375e36a4cf4945c85d16a4ca1aa19',\n",
       " 'f6eb49921df61cbee7eb598fb155daf5',\n",
       " '5bd171ffc4c583ee1c957253744e26b',\n",
       " '96e307cdf15030d8611a1342e10aa229',\n",
       " '16a112db06509196118650abcf2f401b',\n",
       " 'de1d07a6c46d36422f1d36b38986e365',\n",
       " '6b81e745d7df80eeffeee169b6393033',\n",
       " '18c65eb7be7cae25a9bed187c1e5025',\n",
       " '17786b7a4a1a31775af8ae786b4e4711',\n",
       " '61bc318c9a71269923d587220efa06bc',\n",
       " '3bd750351274e5a184835d6aaa3dab42',\n",
       " 'ea48b6d2b0c462511a3bda3560371f8e',\n",
       " 'fd1084709f17ab8e75ecb0a52f0c7590',\n",
       " '21ff4f165399b66f5778c2a7afc8406a',\n",
       " 'c7b315153ace5d3a0e6723d2f050c162',\n",
       " '808e73fa619d607d3ddcd6bb6011c88c',\n",
       " '9b66f98254522c13a725893e1a1bfe55',\n",
       " '1b993e9ca440c51c3695b30f323de786',\n",
       " 'fca5a75851a1e7a16eb28d60e00c330e',\n",
       " '402aac46a5e4521c4321b7a9abedc4cb',\n",
       " '461c2da8e84bc0efaea1ce76ec3cae1c',\n",
       " '431ab2aae5577bd86bf6a759770aef6d',\n",
       " 'c488172bdffa754d0c512bba855b3571',\n",
       " '17204aa01bf972ad5d06e7cbd7f32687',\n",
       " '963a89d426e77cafb677c409fc371c42',\n",
       " '8664ffd9ffc66bffd511e7aa71aaee8e',\n",
       " '4ca93839063a41cac73623c33a87e3a8',\n",
       " '8ace1f701cb63a5d3ecd4ac95be06d53',\n",
       " 'e1aa3d9d06e8e755c62f9829165c94a6',\n",
       " '35311ea644472da9e5389620513d230a',\n",
       " 'e0d0a1fad96075e9e86c524edc8dd45c',\n",
       " 'ea7924e56eef4851ed492bcc35568d23',\n",
       " '2cbcc248833a5f39f0a12f1c025c8d7e',\n",
       " '505ef65be1c95e5a95e1464976873d84',\n",
       " '4feb8a9b6312cd2a22ce52cd15c10c1c',\n",
       " 'ad79a77451bd6dffd0a9be9622d214d2',\n",
       " 'f27d22ed5f3942eca51dfc53a98f6428',\n",
       " '1a70a60e55028d28a87765cb503459cd',\n",
       " 'a87c7cd408275c822dfed964d746fe9e',\n",
       " 'bafa4d56a3ae91c703f8645923a5f1c7',\n",
       " 'b2324d479f6901e4539b285e057276f3',\n",
       " 'e9c0453ec8b5327ea0a06f68cd55a238',\n",
       " 'e6a6d085a8316ff5e7c588e85989ca02',\n",
       " '98e4ac2f62073eccc45ce16cdfe00a6d',\n",
       " '7c554faa3ffa6ccbdc50aa0f88757e16',\n",
       " '51cc6dbde5f9165a33733bdbb3d30f18',\n",
       " 'e5831020c1a648eac852db9964c0efed',\n",
       " '40ea7957e345658cdd33cdc0ff9d8c4d',\n",
       " 'c0889af09180a0864b725899bc25733b',\n",
       " '9ab69cedbd7544f1fb6b4d5237f3ce6c',\n",
       " 'd4883fd0096f61383699f16b08445285',\n",
       " 'fb640a2da30c74b335036461f7325991',\n",
       " '52f99f5f1ebe1dfa390fd49338b88cb7',\n",
       " '14cbf86d8027f6d67758248621544cc4',\n",
       " 'e8ff395d16ea9220830b106f3cfb9857',\n",
       " 'a4c453aa8b05d52ad7e22ca93b6d4c5b',\n",
       " 'c36763a013b30836a5b740be9cd64baa',\n",
       " '39b92dcc2bf25db95528628d51746878',\n",
       " '938dca9d0fc7ff24b7fbd79a281e73ec',\n",
       " 'a61ea15353e630d3ce7278031e243e51',\n",
       " '1192a969669db073d12368d7c1a98b4b',\n",
       " 'b0a3dc9f32f745213eb4a18f23fe322c',\n",
       " 'a022731e75ef7862f1f96e2359e84d6c',\n",
       " '78aed4708aff3c14810218ae8e91545c',\n",
       " 'ace9d5bdbec7af313f4fc8c46c57bdb7',\n",
       " 'e005829f206cb854386e12dd60006473',\n",
       " '6539e35636b7b5854670de6b50d4b22e',\n",
       " '77fd6710f2544ced7f3195660050db87',\n",
       " 'e6154968e0a2f3fec14c5b931e0e4632',\n",
       " '3d7afb33a6841ff0e4a26d837cad8aa4',\n",
       " '4710e1ea36e0fc4ee1d8efc3f1f3fe63',\n",
       " '14dce03c0327838c4e2395cff3210196',\n",
       " '7e2fcd34f0e6d71f54504451472c48d8',\n",
       " 'c05a08bdf0a7574435cf49e7e1464e3d',\n",
       " 'e0bcc4991b60170309c771032d0e6466',\n",
       " 'afc8c340d3215b67051e55dcebe6cd9d',\n",
       " 'ae5f45d325747f22914802a9e4e51490',\n",
       " '85e270b35506700f42a9af4c1a413ff6',\n",
       " '96cb6a5f560216742ea9fd3098416d33',\n",
       " 'a44c33ca1bafaf7488cba6eb654fcfec',\n",
       " '69613a5edbf211e73f4703ffd03aa5',\n",
       " '43c3da28eb5b4b8e44248344ba2104f3',\n",
       " 'c2cc3c81564d4ad7e6d85a9b72bdc523',\n",
       " '4ed615f5a5d1e603c6406687e44179d6',\n",
       " '751946284372e8714e22369f1b511bde',\n",
       " 'a0e1c38bb4e0143f50a3de55865f53',\n",
       " '62bbbb399e223696d8251c9bc14b6e52',\n",
       " 'a589c3bad9a98403351e18eaa493b156',\n",
       " 'f071984c17355f5bef58e50279825884',\n",
       " '3b72048e2c06752e4907176715b9e9b8',\n",
       " 'da656b0cb6f2d444ca0646f4ee06f3ce',\n",
       " '573b4fddc20fda3d949bc4d6fb16c35d',\n",
       " '85d4b946c7cdd820aa4815cd4aefcfa6',\n",
       " '17e2ac5088ab4db67990a3d1f6fce4fa',\n",
       " 'e9e6029b9592e6a0face54660d4dc5bd',\n",
       " 'eeba5c9661c4e9fd1c1aad4db24b14cb',\n",
       " 'fdff569224c3a9039174a85d516d4f0a',\n",
       " 'bb52b0368d94b2c1fdfb57c593b1ba99',\n",
       " '59fe616063977a3bf0da8c429f4bf001',\n",
       " '9744459b5393f155352ac1150fde7089',\n",
       " 'c80c39d3f40312b7eb5881ca6c5cbbbb',\n",
       " '6831e48ede0e076813deb1f6dc105b8d',\n",
       " '11085a5f7e0a1716e80150b8312b92e7',\n",
       " '542f9aec704e8de1744d0a1908e5892a',\n",
       " '1d5dc8d5de605286f71b78d612209057',\n",
       " 'dc62435716e21561bf937e367ad7564d',\n",
       " 'd6adcde3546c2c706459d6f5203280ef',\n",
       " 'c1cf4ab44d42112ea8bddf97fd3104ab',\n",
       " 'dd78aa5d9daa42408fd371b9b8ec8665',\n",
       " 'f572e095851ac9e4cb03531850eac437',\n",
       " '1f17707ce9cecbd0627a948394c07fbb',\n",
       " 'f1d1cafa03c2af64fe611f5ee189e86',\n",
       " '8dc35e636d8281351c42e235337bf6d5',\n",
       " '8f89afff874f4022451d5641c1ad529c',\n",
       " '2aae36fbe7a9a6a1c681536868a3a767',\n",
       " 'b8658cd10b01ad1b6473582ad3fba2a2',\n",
       " 'c105e1590756b0368acc289ad751991f',\n",
       " '66aa1a4b04dc65582a82acfdf6000146',\n",
       " 'c816d51324c1e9926907dd48022ef99a',\n",
       " '5a36289c3123b0f8b7a2eeff56140293',\n",
       " 'afbefd1d903e6fea34747cfff46b896f',\n",
       " 'c429ebf49ea003a2250047c389cdf3a1',\n",
       " '9dd705d64751ad5065c6daad29043186',\n",
       " '7b293d9e2f71c6dd755fdff6c547a321',\n",
       " '891e5863b61652b3babdc8305e269d3d',\n",
       " '7ac4db058b260536930a465ba2e15d4a',\n",
       " '6761df00a4b646633a10f23f9486635a',\n",
       " '75bd80f80502dbe7cf0a8b7cdff70eb',\n",
       " 'a06b134970ed75262925792fdd2763ae',\n",
       " '7c653f5e36a20a6e663fde95c886778c',\n",
       " '247d26a441783915c4a61cf249d443d0',\n",
       " 'ebd7dd7e794165b2272be619e0184d09',\n",
       " 'df9b98158b24b193732837a57e673fb',\n",
       " '573446d80cf581bb957b6d7fc66680de',\n",
       " 'b5d3143d526dfe48d358e0debdb5a534',\n",
       " 'c075ed2504a48482c01f22008c16c698',\n",
       " '647428f5d750e1c664169ce2a864bce8',\n",
       " '4270eb43092bf6505ab95746999fdb90',\n",
       " 'be7e223030261a91f518710bf22f90e0',\n",
       " '654010922ac946d6176064e21ba6bbfd',\n",
       " '27440b98a8d6084cb3c66d1b47dcfaf7',\n",
       " '79e860657650cf1f61bbee4462683740',\n",
       " 'a7ecbdfc1d1436fdd320223e07e81717',\n",
       " '8d6d05531805ed055d1cfbb5f1145369',\n",
       " '63d503d805243efcaebc291f14fa249e',\n",
       " '16e5744186fd2962e2e624f4b20e7f65',\n",
       " 'd0702067a300208d83d7862b09c71811',\n",
       " 'd525906250fd7be11bb41f2d50fc094d',\n",
       " '94742df804d571e2cb2788572f1df3f6',\n",
       " 'ea49d2ad7d69cd6ac8969cbe62022fff',\n",
       " '9b51f868b8637ed2de77fcfb0997034f',\n",
       " '535eba424f8a91d5a4010620dcd10e75',\n",
       " '2ccb97d72dd829fc9778531df84f2003',\n",
       " '90554fad95f86fb04830e387def8a4a0',\n",
       " '9d4454f45d52a2328f92f58a1107be76',\n",
       " 'e53eac0768581bcfc84fb0556bb3572a',\n",
       " '43c61c06b511decd3cc84e995e121ad7',\n",
       " '3a347e9ddea01b26d91e5f972ee273d1',\n",
       " '324b77c8cd7ba563043468bb526cf799',\n",
       " '8bd411cdae8acd3f58b9c02de2214761',\n",
       " '676c5e98388a32f0b5ac7ef27ea13f2f',\n",
       " '9e50dc0df23a6f58bc74386f892aa9e0',\n",
       " 'cd5a1bfb6dfcffe73658dfd2e70bda62',\n",
       " 'ae0a664d0d5af093cc7a2f1fc9cd8588',\n",
       " '2573278343ab1907b6619d822d022541',\n",
       " '99b9380db754dc6913bb728793be6101',\n",
       " 'f8439dbcfcae04d02c18fd3e225ed9b0',\n",
       " '9bee01e6fd7f9044203bf2ab9102c030',\n",
       " '338e4dd3d22f092d0c674cb6d4214e2e',\n",
       " '9ecc13c0e1c0ed5c19e62d26bfdf9294',\n",
       " 'a844bd3d3e75aa6d330b7634562de9b0',\n",
       " '86777c8f2d6c230989552f4b4d27aae0',\n",
       " '4ace431df4d6c9857d2495266d5f6761',\n",
       " 'ef78456a014ef9aeea85eaa3ea23aacb',\n",
       " 'efdc5244ec384b8601522416b7376b1a',\n",
       " 'f5383c8da9416c470b676ea6be48cf76',\n",
       " '63522445469c0c629d129409875da92c',\n",
       " 'b1525b2090db6e015b7a13d9257d5158',\n",
       " 'f9b05a593416d88d4ed1efb9a6915892',\n",
       " '8e3db0786ef4c58e2bd29e075f23ddf8',\n",
       " 'b3ce4efb75f1e337f878796fc77a73eb',\n",
       " 'cbefd2d9a26cd62342ddf12ececbbf0e',\n",
       " '7856b1a0ad44c653052d29da3ea25ee1',\n",
       " '6cca2f4d024be49975b5da78e5b82b12',\n",
       " '7da28ca96b49fdb0c078c36781b57ef3',\n",
       " '3e7d24da59e7c1c61a6b5005a8d9d464',\n",
       " '93bf7f6821f500acd79ff9de20426894',\n",
       " '3d820bb35b91c5f73b5c9bfa49d2cf86',\n",
       " '29a56e9d4fb0a136d07a7bc1158c5f70',\n",
       " '972e04a7e1f5c605b053de8bd7e47cff',\n",
       " '8bba5487c4b0f82ebf610eb5743a1418',\n",
       " 'e18fc791a426996b9507c1a2e1834ea4',\n",
       " '2dab57b7eb0ec03586fa2b99a42b651e',\n",
       " '24f9c3cd8560da91bf7f452fc4b970e3',\n",
       " '2b84e244cb680e3cbe5e7e2042c6bede',\n",
       " '52570b2dd9857569e64f0c89f2ff8a12',\n",
       " '5c36c0a19708d1ced7a6fd7fdd9e5065',\n",
       " '1f250732329aa26dd581271c46627e04',\n",
       " '2ee981a962f486ee544ec3b7aee225b6',\n",
       " 'f39b5e009a4b232c375895a2f6532551',\n",
       " 'e65dee8403f17a0de6e039d093fe6247',\n",
       " '8ef7238792ac95977340b0fc72827c43',\n",
       " 'b9140fb7ddbfbdeb61ae7700dae46a3e',\n",
       " '68cb553e5870f68e2a606b409353720b',\n",
       " '673b4d67361a2f862a753b9e9b95a1a0',\n",
       " 'bfbd28cd743afbe90d40fe6f99e37752',\n",
       " '392475d6bd49445d1f823964a144f37d',\n",
       " '9d0ccf3e5de9e65bcbeddec284f2148b',\n",
       " '9db0f64748e957d864a6770bfbb05e25',\n",
       " 'cea6f3e0edf2300ecd6889cc00fc42d2',\n",
       " '8d070fc489faaf67d670fead0868320b',\n",
       " '1681c5d22501dc8e23fdf92a603783bb',\n",
       " 'e4ecd6f3adf6763dfab1bdfd536c86fd',\n",
       " 'a1148f1393f56cbcd823435fbf36d860',\n",
       " '19c74ff1dd6f738a26c9bd899b2335db',\n",
       " 'd779a9f1c9c46b8cda9cde103e7317f2',\n",
       " '7303a99729eff0f37b208496df1e2328',\n",
       " '4713c60468bf0c6544cca1c0878474da',\n",
       " '94366812473bcdb6230ce82d1df1087c',\n",
       " 'c7f1e5cf41f0c4831167e6ec362e6744',\n",
       " 'bf82707b95b85da4bca548008821723',\n",
       " 'b8bdc5bc37480246f165a92c213ee0fb',\n",
       " '6430fa9b026ae6423d71fae821e1211c',\n",
       " '238d912f14365538bd2a6a7ff24bff76',\n",
       " '8fd597ba025e8d6e4ca88fc3901b7b71',\n",
       " '7a0d8f93261510c51b35cb65edeb0d2c',\n",
       " 'fe527914e84dc0c766d45f64d39332bf',\n",
       " 'e025fd247ef4764169d6523ad1b6a769',\n",
       " '25a37431343f60e3295aa78142651efd',\n",
       " '99e03ec7afc57a670b981874ebec6943',\n",
       " 'ed36f0d947b27fa8ef607e981b624115',\n",
       " 'fbfb7369f7041542974bc736bf626700',\n",
       " '637f3d2a30487286388da23a6b84ccb1',\n",
       " '2c8a1a457d5bf862db328316d401769',\n",
       " 'bcd093a0a9a62def9da3254e825f19ef',\n",
       " 'adf10e893118f71a3a47acc27a9495aa',\n",
       " '9a3b0a8fd9d5ab110f67ebc8cc936c0d',\n",
       " 'e4267670eb6e8c1a8c68c585b764168b',\n",
       " '64056b67a1e8b7c6b57b5b57e081c8dc',\n",
       " 'bb34e99b3aca5c62be390c49e7ded0c1',\n",
       " 'd730042d66fc2379d35edb54b935cf58',\n",
       " '49b51fd2ab8ce7130f297239513840e2',\n",
       " 'c90f2ba0a55f51ca67a284f404ac8a03',\n",
       " '7f04409aade082da1aad1d0575075a8',\n",
       " 'a6854f3bfcd67aaf85ba279a891d2c1e',\n",
       " '6c7c7bc9741d87fd6b1cb8b82e2fbce',\n",
       " 'a952a208968d082689294b8017490ff4',\n",
       " 'da168db3c76e7f3e9c3429d4fc718bb2',\n",
       " '86f034776a5cdf94894bd7508067d96c',\n",
       " '1a028d1fc98a49b102e54179dd477336',\n",
       " '5161b62b73902f8511f7918a87e237bb',\n",
       " '643c085356ad8c142b4efc86bbf7d9af']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossVal_splits[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0a3700",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bfe625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "samples = 2 * _NUM_AUTHORS_ * int(100 / _TWEET_BATCH_SIZE_)\n",
    "_LOGGING_STEPS_ = int(samples / _BATCH_SIZE_)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate               = _LEARNING_RATE_,\n",
    "    num_train_epochs            = _EPOCHS_,\n",
    "    per_device_train_batch_size = _BATCH_SIZE_,\n",
    "    per_device_eval_batch_size  = 200,\n",
    "    logging_steps               = _LOGGING_STEPS_,\n",
    "    output_dir                  = _OUTPUT_DIR_,\n",
    "    save_total_limit            = 10,\n",
    "    overwrite_output_dir        = True,\n",
    "    remove_unused_columns       = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "716df656",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at pysentimiento/robertuito-base-uncased were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pysentimiento/robertuito-base-uncased and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10240\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3200' max='3200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3200/3200 09:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.560600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.535200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.526700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.517200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.512800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.513400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.506300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.497600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>0.492800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.490600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkPointsFE/checkpoint-500\n",
      "Configuration saved in checkPointsFE/checkpoint-500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-1000\n",
      "Configuration saved in checkPointsFE/checkpoint-1000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-1500\n",
      "Configuration saved in checkPointsFE/checkpoint-1500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-2000\n",
      "Configuration saved in checkPointsFE/checkpoint-2000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-2500\n",
      "Configuration saved in checkPointsFE/checkpoint-2500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-3000\n",
      "Configuration saved in checkPointsFE/checkpoint-3000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-3000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 200\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 840/840 [00:38<00:00, 21.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with split 1:\n",
      "\n",
      "soft voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7264    0.7524    0.7392       420\n",
      "           1     0.7432    0.7167    0.7297       420\n",
      "\n",
      "    accuracy                         0.7345       840\n",
      "   macro avg     0.7348    0.7345    0.7344       840\n",
      "weighted avg     0.7348    0.7345    0.7344       840\n",
      " \n",
      "\n",
      "hard voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7105    0.7714    0.7397       420\n",
      "           1     0.7500    0.6857    0.7164       420\n",
      "\n",
      "    accuracy                         0.7286       840\n",
      "   macro avg     0.7303    0.7286    0.7281       840\n",
      "weighted avg     0.7303    0.7286    0.7281       840\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/pysentimiento/robertuito-base-uncased/resolve/main/config.json from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/5212cb9b5b32726fce956daa9a21ee0a0c2b6e54c54d1af58c678217d85f8143.4cce50d5a926bf18fe43f2ea8d4596b505e97a64e6e700e993def66b06f1c83b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"pysentimiento/robertuito-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/pysentimiento/robertuito-base-uncased/resolve/main/pytorch_model.bin from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/8b04e6b193dae308280a39e7414ec9e55aa85418ff297d0e509550de00b93630.273dce86eeb4b83137e2e5511e720f2949cafbe41d618f259e97749592c88fdb\n",
      "Some weights of the model checkpoint at pysentimiento/robertuito-base-uncased were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pysentimiento/robertuito-base-uncased and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10240\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3200' max='3200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3200/3200 12:04, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.573700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.542700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.528500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.523900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.519900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.513100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.508800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.506100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>0.501700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.498400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkPointsFE/checkpoint-500\n",
      "Configuration saved in checkPointsFE/checkpoint-500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-1000\n",
      "Configuration saved in checkPointsFE/checkpoint-1000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-1500\n",
      "Configuration saved in checkPointsFE/checkpoint-1500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-2000\n",
      "Configuration saved in checkPointsFE/checkpoint-2000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-2500\n",
      "Configuration saved in checkPointsFE/checkpoint-2500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-3000\n",
      "Configuration saved in checkPointsFE/checkpoint-3000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-3000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 200\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 840/840 [00:59<00:00, 14.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with split 2:\n",
      "\n",
      "soft voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7407    0.7548    0.7476       420\n",
      "           1     0.7500    0.7357    0.7428       420\n",
      "\n",
      "    accuracy                         0.7452       840\n",
      "   macro avg     0.7453    0.7452    0.7452       840\n",
      "weighted avg     0.7453    0.7452    0.7452       840\n",
      " \n",
      "\n",
      "hard voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7358    0.7690    0.7520       420\n",
      "           1     0.7581    0.7238    0.7406       420\n",
      "\n",
      "    accuracy                         0.7464       840\n",
      "   macro avg     0.7469    0.7464    0.7463       840\n",
      "weighted avg     0.7469    0.7464    0.7463       840\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/pysentimiento/robertuito-base-uncased/resolve/main/config.json from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/5212cb9b5b32726fce956daa9a21ee0a0c2b6e54c54d1af58c678217d85f8143.4cce50d5a926bf18fe43f2ea8d4596b505e97a64e6e700e993def66b06f1c83b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"pysentimiento/robertuito-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/pysentimiento/robertuito-base-uncased/resolve/main/pytorch_model.bin from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/8b04e6b193dae308280a39e7414ec9e55aa85418ff297d0e509550de00b93630.273dce86eeb4b83137e2e5511e720f2949cafbe41d618f259e97749592c88fdb\n",
      "Some weights of the model checkpoint at pysentimiento/robertuito-base-uncased were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pysentimiento/robertuito-base-uncased and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10240\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3200' max='3200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3200/3200 11:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.582600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.550800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.544100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.536700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.523500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.523600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.519000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>0.511800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.510600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkPointsFE/checkpoint-500\n",
      "Configuration saved in checkPointsFE/checkpoint-500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-1000\n",
      "Configuration saved in checkPointsFE/checkpoint-1000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-1500\n",
      "Configuration saved in checkPointsFE/checkpoint-1500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-2000\n",
      "Configuration saved in checkPointsFE/checkpoint-2000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-2500\n",
      "Configuration saved in checkPointsFE/checkpoint-2500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-3000\n",
      "Configuration saved in checkPointsFE/checkpoint-3000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-3000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 200\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 840/840 [00:37<00:00, 22.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with split 3:\n",
      "\n",
      "soft voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7311    0.6667    0.6974       420\n",
      "           1     0.6937    0.7548    0.7229       420\n",
      "\n",
      "    accuracy                         0.7107       840\n",
      "   macro avg     0.7124    0.7107    0.7102       840\n",
      "weighted avg     0.7124    0.7107    0.7102       840\n",
      " \n",
      "\n",
      "hard voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7185    0.6929    0.7055       420\n",
      "           1     0.7034    0.7286    0.7158       420\n",
      "\n",
      "    accuracy                         0.7107       840\n",
      "   macro avg     0.7110    0.7107    0.7106       840\n",
      "weighted avg     0.7110    0.7107    0.7106       840\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/pysentimiento/robertuito-base-uncased/resolve/main/config.json from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/5212cb9b5b32726fce956daa9a21ee0a0c2b6e54c54d1af58c678217d85f8143.4cce50d5a926bf18fe43f2ea8d4596b505e97a64e6e700e993def66b06f1c83b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"pysentimiento/robertuito-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/pysentimiento/robertuito-base-uncased/resolve/main/pytorch_model.bin from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/8b04e6b193dae308280a39e7414ec9e55aa85418ff297d0e509550de00b93630.273dce86eeb4b83137e2e5511e720f2949cafbe41d618f259e97749592c88fdb\n",
      "Some weights of the model checkpoint at pysentimiento/robertuito-base-uncased were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pysentimiento/robertuito-base-uncased and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10240\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3200' max='3200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3200/3200 09:42, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.578400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.548600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.542600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.534200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.525200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.522600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.515800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>0.508100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.512100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkPointsFE/checkpoint-500\n",
      "Configuration saved in checkPointsFE/checkpoint-500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-1000\n",
      "Configuration saved in checkPointsFE/checkpoint-1000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-1500\n",
      "Configuration saved in checkPointsFE/checkpoint-1500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-2000\n",
      "Configuration saved in checkPointsFE/checkpoint-2000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-2500\n",
      "Configuration saved in checkPointsFE/checkpoint-2500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-3000\n",
      "Configuration saved in checkPointsFE/checkpoint-3000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-3000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 200\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 840/840 [00:44<00:00, 18.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with split 4:\n",
      "\n",
      "soft voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7323    0.8143    0.7711       420\n",
      "           1     0.7909    0.7024    0.7440       420\n",
      "\n",
      "    accuracy                         0.7583       840\n",
      "   macro avg     0.7616    0.7583    0.7576       840\n",
      "weighted avg     0.7616    0.7583    0.7576       840\n",
      " \n",
      "\n",
      "hard voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7208    0.8238    0.7689       420\n",
      "           1     0.7944    0.6810    0.7333       420\n",
      "\n",
      "    accuracy                         0.7524       840\n",
      "   macro avg     0.7576    0.7524    0.7511       840\n",
      "weighted avg     0.7576    0.7524    0.7511       840\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/pysentimiento/robertuito-base-uncased/resolve/main/config.json from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/5212cb9b5b32726fce956daa9a21ee0a0c2b6e54c54d1af58c678217d85f8143.4cce50d5a926bf18fe43f2ea8d4596b505e97a64e6e700e993def66b06f1c83b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"pysentimiento/robertuito-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/pysentimiento/robertuito-base-uncased/resolve/main/pytorch_model.bin from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/8b04e6b193dae308280a39e7414ec9e55aa85418ff297d0e509550de00b93630.273dce86eeb4b83137e2e5511e720f2949cafbe41d618f259e97749592c88fdb\n",
      "Some weights of the model checkpoint at pysentimiento/robertuito-base-uncased were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pysentimiento/robertuito-base-uncased and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10240\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3200' max='3200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3200/3200 09:41, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.581300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.558000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.540500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.541400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.532700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.524700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.525200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.517400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>0.517500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.510600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkPointsFE/checkpoint-500\n",
      "Configuration saved in checkPointsFE/checkpoint-500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-1000\n",
      "Configuration saved in checkPointsFE/checkpoint-1000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-1500\n",
      "Configuration saved in checkPointsFE/checkpoint-1500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-2000\n",
      "Configuration saved in checkPointsFE/checkpoint-2000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-2500\n",
      "Configuration saved in checkPointsFE/checkpoint-2500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-3000\n",
      "Configuration saved in checkPointsFE/checkpoint-3000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-3000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 16800\n",
      "  Batch size = 200\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 840/840 [00:29<00:00, 28.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with split 5:\n",
      "\n",
      "soft voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7190    0.7857    0.7509       420\n",
      "           1     0.7638    0.6929    0.7266       420\n",
      "\n",
      "    accuracy                         0.7393       840\n",
      "   macro avg     0.7414    0.7393    0.7387       840\n",
      "weighted avg     0.7414    0.7393    0.7387       840\n",
      " \n",
      "\n",
      "hard voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7119    0.8119    0.7586       420\n",
      "           1     0.7812    0.6714    0.7222       420\n",
      "\n",
      "    accuracy                         0.7417       840\n",
      "   macro avg     0.7465    0.7417    0.7404       840\n",
      "weighted avg     0.7465    0.7417    0.7404       840\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from tools.DataLoaders import DatasetCrossVal\n",
    "from transformers import Trainer\n",
    "from tools.Testing import compute_author_predictions\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import pickle\n",
    "\n",
    "\n",
    "# train\n",
    "\n",
    "task = 'gender'\n",
    "\n",
    "f1s_soft = []\n",
    "f1s_hard = []\n",
    "\n",
    "for split in range( _K_FOLD_CV_ ):\n",
    "    \n",
    "    # loaders for current split ------------------------------------------\n",
    "    \n",
    "    authors_train, authors_val = crossVal_splits[split]\n",
    "    \n",
    "    Train = DatasetCrossVal(baseTrain, authors_train, task)\n",
    "    Val   = DatasetCrossVal(baseTrain, authors_val  , task)\n",
    "    \n",
    "    \n",
    "    # initialize model ---------------------------------------------------\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(_PRETRAINED_LM_, num_labels = 2)\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'classifier' in name:\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    # create trainer and train -------------------------------------------\n",
    "        \n",
    "    trainer = Trainer(\n",
    "        model           = model,\n",
    "        args            = training_args,\n",
    "        train_dataset   = Train,\n",
    "    )\n",
    "    trainer.args._n_gpu = _NO_GPUS_\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    \n",
    "    # get predictions ----------------------------------------------------\n",
    "    \n",
    "    results            = trainer.predict(Val)\n",
    "    author_predictions = compute_author_predictions(Val, results.predictions, 'gender', 2)\n",
    "    \n",
    "    \n",
    "    # report metrics -----------------------------------------------------\n",
    "    \n",
    "    report = {'soft': classification_report(author_predictions['true'], author_predictions['pred_soft'], digits=4), \n",
    "               'hard': classification_report(author_predictions['true'], author_predictions['pred_hard'], digits=4)}\n",
    "\n",
    "    f1s_soft.append( f1_score(author_predictions['true'], author_predictions['pred_soft'], average = 'macro') )\n",
    "    f1s_hard.append( f1_score(author_predictions['true'], author_predictions['pred_hard'], average = 'macro') )\n",
    "\n",
    "    print(\"Results with split \" + str(split + 1) + \":\\n\")\n",
    "    print(\"soft voting:\\n\", report['soft'], '\\n')\n",
    "    print(\"hard voting:\\n\", report['hard'])\n",
    "     \n",
    "    \n",
    "    # save predictions ----------------------------------------------------\n",
    "    \n",
    "    DIR = 'results/' + _DATASET_ + '/' + _LANGUAGE_ + '/' + _PRED_DIR_ + '/' + str(_NUM_AUTHORS_) + '_authors/split_' + str(split + 1) + '/'\n",
    "    if not os.path.exists(DIR):\n",
    "        os.makedirs(DIR)\n",
    "\n",
    "    with open(DIR + 'predictions.pickle', 'wb') as f:\n",
    "        pickle.dump(author_predictions, f)\n",
    "\n",
    "    with open(DIR + 'report.txt', 'w') as f:\n",
    "        f.write(\"soft voting:\\n\" + report['soft'] + '\\n\\n')\n",
    "        f.write(\"hard voting:\\n\" + report['hard'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a56aa6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft results:  [0.7344391281233387, 0.7452149854862119, 0.7101519245815648, 0.7575743789727192, 0.7387225013102223]\n",
      "\n",
      "Hard results:  [0.7280719689225106, 0.746298772472878, 0.7106220095693779, 0.7511111111111111, 0.7403858890017219]\n",
      "\n",
      "\n",
      "Soft statistics: \n",
      "\t[avg, std]: [0.7372205836948115, 0.015626208753411898]\n",
      "\n",
      "Hard statistics: \n",
      "\t[avg, std]: [0.7352979502155199, 0.014547014273443326]\n"
     ]
    }
   ],
   "source": [
    "# report statistics\n",
    "\n",
    "print('Soft results: ', f1s_soft)\n",
    "print('\\nHard results: ', f1s_hard)\n",
    "\n",
    "f1s_soft = np.array(f1s_soft)\n",
    "f1s_hard = np.array(f1s_hard)\n",
    "\n",
    "FewShot_Results = {'soft': [f1s_soft.mean(), f1s_soft.std()], 'hard': [f1s_hard.mean(), f1s_hard.std()]}\n",
    "\n",
    "print('\\n\\nSoft statistics: ')\n",
    "print('\\t[avg, std]:', FewShot_Results['soft'])\n",
    "\n",
    "print('\\nHard statistics: ')\n",
    "print('\\t[avg, std]:', FewShot_Results['hard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dda12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230d0e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7984a07",
   "metadata": {},
   "source": [
    "## Test the best split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "491d18c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/pysentimiento/robertuito-base-uncased/resolve/main/config.json from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/5212cb9b5b32726fce956daa9a21ee0a0c2b6e54c54d1af58c678217d85f8143.4cce50d5a926bf18fe43f2ea8d4596b505e97a64e6e700e993def66b06f1c83b\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"pysentimiento/robertuito-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/pysentimiento/robertuito-base-uncased/resolve/main/pytorch_model.bin from cache at /001/usuarios/isaac.bribiesca/.cache/huggingface/transformers/8b04e6b193dae308280a39e7414ec9e55aa85418ff297d0e509550de00b93630.273dce86eeb4b83137e2e5511e720f2949cafbe41d618f259e97749592c88fdb\n",
      "Some weights of the model checkpoint at pysentimiento/robertuito-base-uncased were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pysentimiento/robertuito-base-uncased and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10240\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3200' max='3200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3200/3200 10:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.578400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.548600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.542600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.534200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>0.525200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>0.522600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>0.515800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>0.508100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.512100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkPointsFE/checkpoint-500\n",
      "Configuration saved in checkPointsFE/checkpoint-500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-1000\n",
      "Configuration saved in checkPointsFE/checkpoint-1000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-1500\n",
      "Configuration saved in checkPointsFE/checkpoint-1500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-2000\n",
      "Configuration saved in checkPointsFE/checkpoint-2000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-2500\n",
      "Configuration saved in checkPointsFE/checkpoint-2500/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to checkPointsFE/checkpoint-3000\n",
      "Configuration saved in checkPointsFE/checkpoint-3000/config.json\n",
      "Model weights saved in checkPointsFE/checkpoint-3000/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 56000\n",
      "  Batch size = 200\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 2800/2800 [05:49<00:00,  8.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with split 4:\n",
      "\n",
      "soft voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7435    0.8157    0.7779      1400\n",
      "           1     0.7959    0.7186    0.7553      1400\n",
      "\n",
      "    accuracy                         0.7671      2800\n",
      "   macro avg     0.7697    0.7671    0.7666      2800\n",
      "weighted avg     0.7697    0.7671    0.7666      2800\n",
      " \n",
      "\n",
      "hard voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7225    0.8293    0.7722      1400\n",
      "           1     0.7997    0.6814    0.7358      1400\n",
      "\n",
      "    accuracy                         0.7554      2800\n",
      "   macro avg     0.7611    0.7554    0.7540      2800\n",
      "weighted avg     0.7611    0.7554    0.7540      2800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from tools.DataLoaders import DatasetCrossVal, DatasetPAN17\n",
    "from transformers import Trainer\n",
    "from tools.Testing import compute_author_predictions\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import pickle\n",
    "\n",
    "\n",
    "# train\n",
    "\n",
    "task = 'gender'\n",
    "\n",
    "split = 3\n",
    "\n",
    "# loaders for current split ------------------------------------------\n",
    "    \n",
    "authors_train, authors_val = crossVal_splits[split]\n",
    "\n",
    "Train = DatasetCrossVal(baseTrain, authors_train, task)\n",
    "Val   = DatasetCrossVal(baseTrain, authors_val  , task)\n",
    "\n",
    "\n",
    "# initialize model ---------------------------------------------------\n",
    "    \n",
    "model = AutoModelForSequenceClassification.from_pretrained(_PRETRAINED_LM_, num_labels = 2)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if 'classifier' in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# create trainer and train -------------------------------------------\n",
    "\n",
    "trainer = Trainer(\n",
    "    model           = model,\n",
    "    args            = training_args,\n",
    "    train_dataset   = Train,\n",
    ")\n",
    "trainer.args._n_gpu = _NO_GPUS_\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# get predictions ----------------------------------------------------\n",
    "\n",
    "results            = trainer.predict(Test)\n",
    "author_predictions = compute_author_predictions(baseTest, results.predictions, 'gender', 2)\n",
    "\n",
    "\n",
    "# report metrics -----------------------------------------------------\n",
    "\n",
    "report = {'soft': classification_report(author_predictions['true'], author_predictions['pred_soft'], digits=4), \n",
    "           'hard': classification_report(author_predictions['true'], author_predictions['pred_hard'], digits=4)}\n",
    "\n",
    "print(\"Results with split \" + str(split + 1) + \":\\n\")\n",
    "print(\"soft voting:\\n\", report['soft'], '\\n')\n",
    "print(\"hard voting:\\n\", report['hard'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00349e24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
