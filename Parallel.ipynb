{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5287a8d",
   "metadata": {},
   "source": [
    "## Set Global Seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e68a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The global seed 260615\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed = 260615\n",
    "set_all_seeds(seed)\n",
    "\n",
    "print(\"The global seed \" + str(seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a407e6",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0faaf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANGUAGE\n",
    "\n",
    "_LANGUAGE_         = 'en'\n",
    "_DATASET_          = '2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f81690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL CLASSIFICATION\n",
    "\n",
    "_PRETRAINED_LM_    = 'vinai/bertweet-base'\n",
    "_PREPROCESS_TEXT_  = True\n",
    "_TWEET_BATCH_SIZE_ = 5\n",
    "_ADAPTER_CONFIG_   = transformers.ParallelConfig(reduction_factor = 256)\n",
    "_MAX_SEQ_LEN_      = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daabdab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "\n",
    "_OUTPUT_DIR_       = 'checkPointsParallel'\n",
    "_LOGGING_STEPS_    = 50\n",
    "_NUM_AUTHORS_      = 256\n",
    "_K_FOLD_CV_        = 5\n",
    "_NO_GPUS_          = 1\n",
    "_BATCH_SIZE_       = int(32 / _NO_GPUS_)\n",
    "_EPOCHS_           = 10\n",
    "_LEARNING_RATE_    = 1e-4\n",
    "\n",
    "# PREDICTIONS\n",
    "\n",
    "_PRED_DIR_         = 'Parallel'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2c9214",
   "metadata": {},
   "source": [
    "## Other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b722fcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL DICTONARIES -----------------------------------------------------------------------\n",
    "\n",
    "# 2015\n",
    "\n",
    "age_dict  = {'18-24': 0, '25-34': 1, '35-49': 2, '50-XX': 3}\n",
    "ageEN_hyp = {0: '18-24', 1: '25-34', 2: '35-49', 3: '50-XX'}\n",
    "ageES_hyp = {0: 'La edad de esta persona es entre 18 y 24 años', \n",
    "             1: 'La edad de esta persona es entre 25 y 34 años', \n",
    "             2: 'La edad de esta persona es entre 35 y 49 años', \n",
    "             3: 'La edad de esta persona es más de 50 años'}\n",
    "\n",
    "# 2017\n",
    "\n",
    "gender_dict    = {'female': 0, 'male':   1}\n",
    "varietyEN_dict = {'australia': 0, 'canada': 1, 'great britain': 2, 'ireland': 3, 'new zealand': 4, 'united states': 5}\n",
    "varietyES_dict = {'argentina': 0, 'chile': 1, 'colombia': 2, 'mexico': 3, 'peru': 4, 'spain': 5, 'venezuela': 6}  \n",
    "\n",
    "genderEN_hyp  = {0: 'I’m a female', 1: 'I’m a male'}\n",
    "genderES_hyp  = {0: 'Mi nombre es María', 1: 'Mi nombre es José'}\n",
    "\n",
    "# 2019\n",
    "\n",
    "bots_dict  = {'human': 0, 'bot': 1}\n",
    "botsEN_hyp = {0: 'This is a text from a person', 1: 'This is a text from a machine'}\n",
    "botsES_hyp = {0: 'Humano', 1: 'Bot'}\n",
    "\n",
    "# 2020 \n",
    "\n",
    "fakeNews_dict  = {'0': 0, '1': 1}\n",
    "fakeNewsEN_hyp = {0: 'This author is a normal user', 1: 'This author spreads fake news'}\n",
    "fakeNewsES_hyp = {0: 'Este autor es un usuario normal', 1: 'Este autor publica noticias falsas'}\n",
    "\n",
    "# 2021\n",
    "\n",
    "hateSpeech_dict  = {'0': 0, '1': 1}\n",
    "hateSpeechEN_hyp = {0: 'This text does not contain hate speech', 1: 'This text expresses prejudice and hate speech'}\n",
    "hateSpeechES_hyp = {0: 'Este texto es moderado, respetuoso, cortés y civilizado', 1: 'Este texto expresa odio o prejuicios'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc921f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET LANGUAGE DICTIONARIES --------------------------------------------------\n",
    "\n",
    "if _LANGUAGE_ == 'en':\n",
    "    age_hyp        = ageEN_hyp\n",
    "    gender_hyp     = genderEN_hyp\n",
    "    variety_dict   = varietyEN_dict\n",
    "    fakeNews_hyp   = fakeNewsEN_hyp\n",
    "    hateSpeech_hyp = hateSpeechEN_hyp\n",
    "    bots_hyp       = botsEN_hyp \n",
    "\n",
    "elif _LANGUAGE_ == 'es':\n",
    "    age_hyp        = ageES_hyp\n",
    "    gender_hyp     = genderES_hyp\n",
    "    variety_dict   = varietyES_dict\n",
    "    fakeNews_hyp   = fakeNewsES_hyp\n",
    "    hateSpeech_hyp = hateSpeechES_hyp\n",
    "    bots_hyp       = botsES_hyp\n",
    "    \n",
    "    \n",
    "# SET LANGUAGE AND DATASET PARAMETERS ----------------------------------------\n",
    "    \n",
    "if   _DATASET_ == '2015':\n",
    "    label_idx  = 2\n",
    "    class_dict = age_dict\n",
    "    label_name = 'age'\n",
    "    label_hyp  = age_hyp\n",
    "    \n",
    "elif _DATASET_ == '2017':\n",
    "    label_idx  = 1\n",
    "    class_dict = gender_dict\n",
    "    label_name = 'gender'\n",
    "    label_hyp  = gender_hyp\n",
    "    \n",
    "elif _DATASET_ == '2019':\n",
    "    label_idx  = 1\n",
    "    class_dict = bots_dict\n",
    "    label_name = 'bots'\n",
    "    label_hyp  = bots_hyp\n",
    "    \n",
    "elif _DATASET_ == '2020':\n",
    "    label_idx  = 1\n",
    "    class_dict = fakeNews_dict\n",
    "    label_name = 'fakeNews'\n",
    "    label_hyp  = fakeNews_hyp\n",
    "    \n",
    "elif _DATASET_ == '2021':\n",
    "    label_idx  = 1\n",
    "    class_dict = hateSpeech_dict\n",
    "    label_name = 'hateSpeech'\n",
    "    label_hyp  = hateSpeech_hyp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c35894a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# SET LANGUAGE TOKENIZER\n",
    "\n",
    "from transformers import AutoTokenizer, PretrainedConfig\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(_PRETRAINED_LM_)\n",
    "vocab = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ef9838",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6438e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET AUTHORS AND LABELS -----------------------------------------------------\n",
    "\n",
    "from tools.DataLoaders import BasePAN\n",
    "\n",
    "baseTrain  = BasePAN(Dir        = 'data/' + _DATASET_,\n",
    "                     split      = 'train',\n",
    "                     language   = _LANGUAGE_,\n",
    "                     label_idx  = label_idx,\n",
    "                     class_dict = class_dict,\n",
    "                     label_name = label_name)\n",
    "\n",
    "baseTest   = BasePAN(Dir        = 'data/' + _DATASET_,\n",
    "                     split      = 'test',\n",
    "                     language   = _LANGUAGE_,\n",
    "                     label_idx  = label_idx,\n",
    "                     class_dict = class_dict,\n",
    "                     label_name = label_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a6a42ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e78b60f0-b114-4238-a0b2-dbd52ab12b99',\n",
       " 'eb5cea6d-ecc7-4c1c-b149-dffb4e4d9373',\n",
       " 'c65228f6-59a4-41a9-8d06-788406e5ff7e',\n",
       " 'a1e96b2b-17eb-4450-911b-751a31fadf15',\n",
       " 'ce325322-8731-426d-837a-60ea688fe82d',\n",
       " '541812a8-23ca-40a2-ba5a-2ae0908eada2',\n",
       " '23842323-5699-4551-9ff6-a684dee93a9a',\n",
       " 'f1dcc4ff-0c7c-4fee-9a65-04a13285f327',\n",
       " 'c2253559-eb87-44ac-9a0b-a1d1a0cdfd48',\n",
       " 'ae414abd-cd83-4f0d-bc8c-d0a34a0071a3',\n",
       " '522a6f2f-d308-4b0e-ab31-0ab817e1f5d6',\n",
       " 'f3af2ca2-dbfb-4447-a4f2-dfdfdda58640',\n",
       " '18fc8412-8068-4993-9382-f44d716f092e',\n",
       " 'b7e9f372-21a8-461b-b4f0-950205f84da0',\n",
       " 'dde4cfc8-f4cf-47be-8d9c-21b3b7f63098',\n",
       " '59c19daa-873b-434d-98d9-3b8c0168f946',\n",
       " 'bb414002-cc26-4103-a00b-7f52a72efd59',\n",
       " '4b05f4e0-2b12-48f1-94c0-c55b4caf534c',\n",
       " '92defdbb-307e-4d13-b9ce-703f55adcf79',\n",
       " '1f17c4c3-0942-4fe5-8e03-5ad9f6a514d1',\n",
       " 'fd7c89ad-deb5-4445-99c5-bf4c698ee371',\n",
       " 'b1e938db-2e6c-46b5-a006-213bbada216b',\n",
       " '91c6d3f2-738c-4b86-8f1c-31a2311f987d',\n",
       " '1cd73ab3-e945-4334-ac09-7a1bf62559ab',\n",
       " '8398faf9-5d2b-4613-8547-b31cd47d249e',\n",
       " '60468a75-1938-4366-abaa-5ad1cc1b0b8e',\n",
       " '3a396b48-d99c-4b22-9040-a50b6976f7cd',\n",
       " 'c0f2ba6b-200e-44fb-ac60-81084eec9daa',\n",
       " '956f4dba-c26b-4f12-ae6d-f908c742cadc',\n",
       " '57af56a7-246a-4d59-af27-f1c8e8d231b1',\n",
       " 'ed970294-8f36-4008-a82e-183ac9abf6ac',\n",
       " '2aa1a2fb-ff75-4228-a806-f66c39b292f9',\n",
       " 'daae7fa9-dcc1-4f20-9e97-d3d71123e8ce',\n",
       " '5097f2bf-bb7a-48f3-8c40-278ed7ff655c',\n",
       " '1094e809-1306-4cd1-8ac1-ebfdf7c872b8',\n",
       " 'aa0776b5-03cf-4915-b880-a1cff2b3cf57',\n",
       " 'bb88ec91-6085-4a89-94e0-6ae12a3afd3a',\n",
       " '98d08ed3-5b05-4635-a53e-3e5b774befea',\n",
       " '9f4836b6-5ba0-4523-a161-199c6ee97627',\n",
       " '5f8d6f5f-b051-4db0-96e9-f5125c74b922',\n",
       " '57c6c6f0-1989-4fe1-895e-1be3194aaf3b',\n",
       " '85879831-9972-484c-8686-103c2bfae297',\n",
       " 'f707b0c7-f11f-480c-b859-c38ecfa201e2',\n",
       " '4c1d5bd8-7bf3-42db-b84c-426aee515a1f',\n",
       " '5836844e-18ac-45ff-b8fe-e26dffbe9f6e',\n",
       " '68321c6d-6e38-4dd3-9a1a-535a25454d9b',\n",
       " '97999fdb-0754-4bf1-9dce-6f0cdec6558f',\n",
       " 'e11d4b1e-42e6-44a6-b067-e0873e566fe3',\n",
       " '5a3757da-1eda-4bb5-bf68-816fa10c2231',\n",
       " 'b38fee80-2fb1-4481-be25-e8297aae928d',\n",
       " '994c8615-1ca7-48e5-9e96-3af155260a18',\n",
       " '69f8e2b2-3fe7-41e7-9096-72dfc34bd736',\n",
       " '6c5201d6-b53a-4638-a299-02aa2f2ce373',\n",
       " '03f72f70-7a00-4dbb-93b7-6c7f65954fc5',\n",
       " 'b3ff1402-beab-4395-a107-56e5fb19c0e9',\n",
       " '493a2b48-98b3-4837-bd04-e32646f78aa3',\n",
       " '88d5bfa3-8612-409c-8216-9c9aac3a64d2',\n",
       " '34e43885-7fae-4207-80f2-853c0eba099a',\n",
       " 'bde7a38f-fd87-4777-a954-d3ec34873d8a',\n",
       " '78fb5696-dc1c-4ea9-b4e4-ae67acd7de72',\n",
       " 'a6323e6d-213e-4105-920c-d375023e5645',\n",
       " 'fde8eb00-0444-4159-9b65-1ead60c2dc88',\n",
       " 'c148f06c-d71a-4c3e-bee0-e35acba6916c',\n",
       " '61c4aca8-6e7f-4da3-9b30-1f99f7656189',\n",
       " '7175696d-d60e-44ed-aebc-1f8582567995',\n",
       " '3be30fbc-698d-48c9-916b-b3a50bf38252',\n",
       " 'e942ba7f-1820-4116-a356-01e2e2530e3e',\n",
       " '98ae4949-8a9c-481c-911c-a3fa49eea244',\n",
       " '2b27ab92-c89d-4529-a238-905974a11cfd',\n",
       " '7418df48-598b-49df-9ccb-be12715c21ea',\n",
       " '70606fb5-7711-4735-b69f-50941e0ba90b',\n",
       " '8f04a1f5-8cbb-4c27-bb1b-7bdc3b0dcc7e',\n",
       " 'e2041e6d-f7c4-4cde-baac-5ae2a7e636cc',\n",
       " 'c4a413a1-1170-4c2c-9f97-3f0bfb474154',\n",
       " '5d719be8-9c09-435f-8dde-3253eb1b3191',\n",
       " '16b423e5-3154-42ef-ad37-3f80858febf5',\n",
       " '99710477-8e8f-4387-b228-d8cc1ca86d17',\n",
       " '3aae4b14-7dfe-4cb7-b82a-629d01d06da0',\n",
       " '1aa8c430-853b-4bbc-b784-df4c88264ccd',\n",
       " '7f98ebb4-a2da-4579-9c3c-0f2fbaafc754',\n",
       " 'de7f0515-32b0-4b1e-9fb9-91a66cd434a3',\n",
       " 'b90df535-3585-40ac-b6ac-59ef4fdab88d',\n",
       " 'a71c93ed-a929-4f59-8728-6639a6d31975',\n",
       " '703806e5-f04b-4e7c-8456-7340784ecf76',\n",
       " '6c51bbf8-f00e-4ddf-8ff5-cf034a6cfbd8',\n",
       " '6a3addbf-f699-482d-ba2f-02248d52db95',\n",
       " '2ae9cc17-b851-4f6a-910e-bf2a2f6d91ab',\n",
       " '0b66092a-440e-4755-a624-759a580a1c70',\n",
       " '3d50490f-f49f-4cb4-86e9-ed57caf70ab4',\n",
       " '17591594-b75c-47c2-be3e-5dcbe6c45286',\n",
       " '68aa0510-c167-41ae-9c3b-8ac8987db0db',\n",
       " 'cd2212cd-c54c-4979-aba7-8c0f43d017e9',\n",
       " '3c608533-476b-4710-b303-d84aaef3ee9d',\n",
       " 'dd453533-94b0-4195-9760-f32d297d8951',\n",
       " '5fea747d-78d3-4baa-915b-1ef6d94c60a7',\n",
       " '1661bc1b-1e6a-4c3d-a6b8-ee21f0730288',\n",
       " '912ab3dd-fbc1-4bdf-a3e0-07a8ce054ece',\n",
       " '4e165fb2-3dac-413a-a38d-696737dd775b',\n",
       " 'b7bc6377-b203-4a28-a24f-6320b9195041',\n",
       " '3f27d01d-1638-49d3-ade5-84e5372cbc9d',\n",
       " 'e27e308c-e187-4f8d-b4cb-d845f6c9203f',\n",
       " 'c657394c-bcbd-4b64-8d3a-820011bc8e23',\n",
       " '0aa7bace-924c-40fb-a2e5-3c7012ede244',\n",
       " '69269faf-28b6-47aa-9fa0-cb4b30c684a6',\n",
       " 'd4e76cdb-11e7-44ca-ad47-2fcf718f2fd8',\n",
       " '11c285a3-599c-4fa4-a166-76cccd5b2478',\n",
       " '97432f40-f518-422d-8a13-b67c78933c32',\n",
       " '25789f19-6181-492d-9f0d-d3b6d07fcc97',\n",
       " 'f28ad171-3a6b-4f88-a3c9-feebe7b86747',\n",
       " '89fab4e9-24f0-4a97-8e10-ca357cc7865c',\n",
       " '68b27ee9-bf56-45db-be9a-2e0970d2b6b8',\n",
       " '81584f97-1167-49e0-8da0-0d4d66f8e238',\n",
       " 'efb846b2-986a-43ae-8b9b-d811f93b52fd',\n",
       " '9f4ca5ba-5075-446c-b93a-c0a93ce9bfbc',\n",
       " '91947b38-5ecd-4b12-957a-26e52198f058',\n",
       " 'aea6d407-5981-42ce-bccf-1d2bf4094543',\n",
       " 'aabae9fc-b393-4124-9a1c-32370eb1adfc',\n",
       " '62bffe2f-1a49-4c79-9f53-ed2e666d41cf',\n",
       " 'ac599f45-3c95-4599-86f1-78a6494011f7',\n",
       " 'd7f46166-6a9a-4b2c-8560-04e27d2ea14d',\n",
       " '5def4eb3-e861-4864-a2f2-669680902007',\n",
       " '9411c815-9eb6-466e-b3e2-1e739510c94b',\n",
       " '1d2a2248-1dbf-4e18-933d-42eeedb3ae7e']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GET K-FOLD SPLITS -----------------------------------------------------\n",
    "\n",
    "crossVal_splits = baseTrain.cross_val(_K_FOLD_CV_, _NUM_AUTHORS_)\n",
    "\n",
    "crossVal_splits[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df486efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading data...\n",
      "    Done\n",
      "Preprocessing text...\n",
      "    Done\n",
      "Tokenizing...\n",
      "    Done\n",
      "Merging data...\n",
      "    Done\n",
      "\n",
      "Total Instances: 2846\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GET TWEETS -----------------------------------------------------\n",
    "\n",
    "baseTrain.get_all_data(_TWEET_BATCH_SIZE_, tokenizer, _MAX_SEQ_LEN_, _PREPROCESS_TEXT_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230d0e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e598c406",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fe235d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading data...\n",
      "    Done\n",
      "Preprocessing text...\n",
      "    Done\n",
      "Tokenizing...\n",
      "    Done\n",
      "Merging data...\n",
      "    Done\n",
      "\n",
      "Total Instances: 2645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tools.DataLoaders import DatasetPAN\n",
    "\n",
    "baseTest.get_all_data(_TWEET_BATCH_SIZE_, tokenizer, _MAX_SEQ_LEN_, _PREPROCESS_TEXT_)\n",
    "\n",
    "Test = DatasetPAN(baseTest, label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42d02df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "samples = 2 * _NUM_AUTHORS_ * int(100 / _TWEET_BATCH_SIZE_)\n",
    "_LOGGING_STEPS_ = int(samples / _BATCH_SIZE_)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate               = _LEARNING_RATE_,\n",
    "    num_train_epochs            = _EPOCHS_,\n",
    "    per_device_train_batch_size = _BATCH_SIZE_,\n",
    "    per_device_eval_batch_size  = 200,\n",
    "    logging_steps               = _LOGGING_STEPS_,\n",
    "    output_dir                  = _OUTPUT_DIR_,\n",
    "    save_total_limit            = 10,\n",
    "    overwrite_output_dir        = True,\n",
    "    remove_unused_columns       = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0dfc823",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaAdapterModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1694\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 530\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='530' max='530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [530/530 01:26, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.197900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.960200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.823500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.771500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.657000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.623400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.567200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.520500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.492200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.477800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.473100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.428700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.437200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkPointsHoulsby/checkpoint-500\n",
      "Configuration saved in checkPointsHoulsby/checkpoint-500/age/adapter_config.json\n",
      "Module weights saved in checkPointsHoulsby/checkpoint-500/age/pytorch_adapter.bin\n",
      "Configuration saved in checkPointsHoulsby/checkpoint-500/age/head_config.json\n",
      "Module weights saved in checkPointsHoulsby/checkpoint-500/age/pytorch_model_head.bin\n",
      "Configuration saved in checkPointsHoulsby/checkpoint-500/age/head_config.json\n",
      "Module weights saved in checkPointsHoulsby/checkpoint-500/age/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2645\n",
      "  Batch size = 200\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 142/142 [00:00<00:00, 2441.25it/s]\n",
      "Adding adapter 'age'.\n",
      "Adding head 'age' with config {'head_type': 'classification', 'num_labels': 4, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2, 'LABEL_3': 3}, 'use_pooler': False, 'bias': True}.\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1717\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with split 1:\n",
      "\n",
      "soft voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9273    0.9107    0.9189        56\n",
      "           1     0.7536    0.8966    0.8189        58\n",
      "           2     0.7857    0.5500    0.6471        20\n",
      "           3     1.0000    0.5000    0.6667         8\n",
      "\n",
      "    accuracy                         0.8310       142\n",
      "   macro avg     0.8667    0.7143    0.7629       142\n",
      "weighted avg     0.8405    0.8310    0.8256       142\n",
      " \n",
      "\n",
      "hard voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9259    0.8929    0.9091        56\n",
      "           1     0.7391    0.8793    0.8031        58\n",
      "           2     0.7333    0.5500    0.6286        20\n",
      "           3     1.0000    0.5000    0.6667         8\n",
      "\n",
      "    accuracy                         0.8169       142\n",
      "   macro avg     0.8496    0.7055    0.7519       142\n",
      "weighted avg     0.8267    0.8169    0.8127       142\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='540' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [540/540 01:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.218900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.943800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.800400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.753600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.657500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.616000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.578300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.548600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.505700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.495700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.452300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.467900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.429300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkPointsHoulsby/checkpoint-500\n",
      "Configuration saved in checkPointsHoulsby/checkpoint-500/age/adapter_config.json\n",
      "Module weights saved in checkPointsHoulsby/checkpoint-500/age/pytorch_adapter.bin\n",
      "Configuration saved in checkPointsHoulsby/checkpoint-500/age/head_config.json\n",
      "Module weights saved in checkPointsHoulsby/checkpoint-500/age/pytorch_model_head.bin\n",
      "Configuration saved in checkPointsHoulsby/checkpoint-500/age/head_config.json\n",
      "Module weights saved in checkPointsHoulsby/checkpoint-500/age/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2645\n",
      "  Batch size = 200\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 142/142 [00:00<00:00, 2377.21it/s]\n",
      "Adding adapter 'age'.\n",
      "Adding head 'age' with config {'head_type': 'classification', 'num_labels': 4, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2, 'LABEL_3': 3}, 'use_pooler': False, 'bias': True}.\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1720\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with split 2:\n",
      "\n",
      "soft voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9600    0.8571    0.9057        56\n",
      "           1     0.7000    0.9655    0.8116        58\n",
      "           2     0.8750    0.3500    0.5000        20\n",
      "           3     1.0000    0.5000    0.6667         8\n",
      "\n",
      "    accuracy                         0.8099       142\n",
      "   macro avg     0.8838    0.6682    0.7210       142\n",
      "weighted avg     0.8441    0.8099    0.7966       142\n",
      " \n",
      "\n",
      "hard voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9057    0.8571    0.8807        56\n",
      "           1     0.6974    0.9138    0.7910        58\n",
      "           2     0.8889    0.4000    0.5517        20\n",
      "           3     1.0000    0.5000    0.6667         8\n",
      "\n",
      "    accuracy                         0.7958       142\n",
      "   macro avg     0.8730    0.6677    0.7225       142\n",
      "weighted avg     0.8235    0.7958    0.7857       142\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='540' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [540/540 01:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.200500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.907900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.776200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.675100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.585700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.555900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.457000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.452900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.444800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.406500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.357600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.371700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.364700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkPointsHoulsby/checkpoint-500\n",
      "Configuration saved in checkPointsHoulsby/checkpoint-500/age/adapter_config.json\n",
      "Module weights saved in checkPointsHoulsby/checkpoint-500/age/pytorch_adapter.bin\n",
      "Configuration saved in checkPointsHoulsby/checkpoint-500/age/head_config.json\n",
      "Module weights saved in checkPointsHoulsby/checkpoint-500/age/pytorch_model_head.bin\n",
      "Configuration saved in checkPointsHoulsby/checkpoint-500/age/head_config.json\n",
      "Module weights saved in checkPointsHoulsby/checkpoint-500/age/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2645\n",
      "  Batch size = 200\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 142/142 [00:00<00:00, 2317.15it/s]\n",
      "Adding adapter 'age'.\n",
      "Adding head 'age' with config {'head_type': 'classification', 'num_labels': 4, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2, 'LABEL_3': 3}, 'use_pooler': False, 'bias': True}.\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1709\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with split 3:\n",
      "\n",
      "soft voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8667    0.9286    0.8966        56\n",
      "           1     0.7705    0.8103    0.7899        58\n",
      "           2     0.7857    0.5500    0.6471        20\n",
      "           3     0.7143    0.6250    0.6667         8\n",
      "\n",
      "    accuracy                         0.8099       142\n",
      "   macro avg     0.7843    0.7285    0.7500       142\n",
      "weighted avg     0.8074    0.8099    0.8049       142\n",
      " \n",
      "\n",
      "hard voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8667    0.9286    0.8966        56\n",
      "           1     0.7869    0.8276    0.8067        58\n",
      "           2     0.7692    0.5000    0.6061        20\n",
      "           3     0.6250    0.6250    0.6250         8\n",
      "\n",
      "    accuracy                         0.8099       142\n",
      "   macro avg     0.7619    0.7203    0.7336       142\n",
      "weighted avg     0.8067    0.8099    0.8036       142\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='540' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [540/540 01:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.235400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.985100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.853100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.751800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.682900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.585200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.601100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.528500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.488400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.489700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.464900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.437800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.422600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkPointsHoulsby/checkpoint-500\n",
      "Configuration saved in checkPointsHoulsby/checkpoint-500/age/adapter_config.json\n",
      "Module weights saved in checkPointsHoulsby/checkpoint-500/age/pytorch_adapter.bin\n",
      "Configuration saved in checkPointsHoulsby/checkpoint-500/age/head_config.json\n",
      "Module weights saved in checkPointsHoulsby/checkpoint-500/age/pytorch_model_head.bin\n",
      "Configuration saved in checkPointsHoulsby/checkpoint-500/age/head_config.json\n",
      "Module weights saved in checkPointsHoulsby/checkpoint-500/age/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2645\n",
      "  Batch size = 200\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 142/142 [00:00<00:00, 2250.12it/s]\n",
      "Adding adapter 'age'.\n",
      "Adding head 'age' with config {'head_type': 'classification', 'num_labels': 4, 'layers': 2, 'activation_function': 'tanh', 'label2id': {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2, 'LABEL_3': 3}, 'use_pooler': False, 'bias': True}.\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1707\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with split 4:\n",
      "\n",
      "soft voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8226    0.9107    0.8644        56\n",
      "           1     0.7031    0.7759    0.7377        58\n",
      "           2     0.6667    0.4000    0.5000        20\n",
      "           3     1.0000    0.5000    0.6667         8\n",
      "\n",
      "    accuracy                         0.7606       142\n",
      "   macro avg     0.7981    0.6466    0.6922       142\n",
      "weighted avg     0.7618    0.7606    0.7502       142\n",
      " \n",
      "\n",
      "hard voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8226    0.9107    0.8644        56\n",
      "           1     0.6984    0.7586    0.7273        58\n",
      "           2     0.6667    0.4000    0.5000        20\n",
      "           3     0.8000    0.5000    0.6154         8\n",
      "\n",
      "    accuracy                         0.7535       142\n",
      "   macro avg     0.7469    0.6423    0.6768       142\n",
      "weighted avg     0.7486    0.7535    0.7430       142\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='540' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [540/540 01:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.234800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.986100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.746800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.672300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.640100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.578800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.537900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.508600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.471200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.469600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.469900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.421600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkPointsHoulsby/checkpoint-500\n",
      "Configuration saved in checkPointsHoulsby/checkpoint-500/age/adapter_config.json\n",
      "Module weights saved in checkPointsHoulsby/checkpoint-500/age/pytorch_adapter.bin\n",
      "Configuration saved in checkPointsHoulsby/checkpoint-500/age/head_config.json\n",
      "Module weights saved in checkPointsHoulsby/checkpoint-500/age/pytorch_model_head.bin\n",
      "Configuration saved in checkPointsHoulsby/checkpoint-500/age/head_config.json\n",
      "Module weights saved in checkPointsHoulsby/checkpoint-500/age/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2645\n",
      "  Batch size = 200\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 142/142 [00:00<00:00, 2386.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with split 5:\n",
      "\n",
      "soft voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9273    0.9107    0.9189        56\n",
      "           1     0.7647    0.8966    0.8254        58\n",
      "           2     0.7143    0.5000    0.5882        20\n",
      "           3     1.0000    0.6250    0.7692         8\n",
      "\n",
      "    accuracy                         0.8310       142\n",
      "   macro avg     0.8516    0.7331    0.7754       142\n",
      "weighted avg     0.8350    0.8310    0.8257       142\n",
      " \n",
      "\n",
      "hard voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9107    0.9107    0.9107        56\n",
      "           1     0.7429    0.8966    0.8125        58\n",
      "           2     0.8182    0.4500    0.5806        20\n",
      "           3     1.0000    0.6250    0.7692         8\n",
      "\n",
      "    accuracy                         0.8239       142\n",
      "   macro avg     0.8679    0.7206    0.7683       142\n",
      "weighted avg     0.8342    0.8239    0.8161       142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoAdapterModel\n",
    "from tools.DataLoaders import DatasetCrossVal\n",
    "from transformers import AdapterTrainer\n",
    "from tools.Testing import compute_author_predictions\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import pickle\n",
    "\n",
    "# initialize base model\n",
    "\n",
    "model = AutoAdapterModel.from_pretrained(_PRETRAINED_LM_)\n",
    "\n",
    "\n",
    "# train\n",
    "\n",
    "task = label_name\n",
    "\n",
    "f1s_soft = []\n",
    "f1s_hard = []\n",
    "\n",
    "for split in range( _K_FOLD_CV_ ):\n",
    "    \n",
    "    # loaders for current split ------------------------------------------\n",
    "    \n",
    "    authors_train, authors_val = crossVal_splits[split]\n",
    "    \n",
    "    Train = DatasetCrossVal(baseTrain, authors_train, task)\n",
    "    Val   = DatasetCrossVal(baseTrain, authors_val  , task)\n",
    "    \n",
    "    \n",
    "    # add adapter --------------------------------------------------------\n",
    "    \n",
    "    model.add_adapter(adapter_name = task,config = _ADAPTER_CONFIG_)\n",
    "    model.add_classification_head(head_name = task, num_labels = len(class_dict))\n",
    "    \n",
    "    model.set_active_adapters(task)\n",
    "    model.train_adapter(task)\n",
    "    \n",
    "    \n",
    "    # create trainer and train -------------------------------------------\n",
    "        \n",
    "    trainer = AdapterTrainer(\n",
    "        model           = model,\n",
    "        args            = training_args,\n",
    "        train_dataset   = Train,\n",
    "    )\n",
    "    trainer.args._n_gpu = _NO_GPUS_\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    \n",
    "    # get predictions ----------------------------------------------------\n",
    "    \n",
    "    results            = trainer.predict(Test)\n",
    "    author_predictions = compute_author_predictions(baseTest, results.predictions, task, len(class_dict))\n",
    "    \n",
    "    \n",
    "    # report metrics -----------------------------------------------------\n",
    "    \n",
    "    report = {'soft': classification_report(author_predictions['true'], author_predictions['pred_soft'], digits=4), \n",
    "               'hard': classification_report(author_predictions['true'], author_predictions['pred_hard'], digits=4)}\n",
    "\n",
    "    f1s_soft.append( f1_score(author_predictions['true'], author_predictions['pred_soft'], average = 'macro') )\n",
    "    f1s_hard.append( f1_score(author_predictions['true'], author_predictions['pred_hard'], average = 'macro') )\n",
    "\n",
    "    print(\"Results with split \" + str(split + 1) + \":\\n\")\n",
    "    print(\"soft voting:\\n\", report['soft'], '\\n')\n",
    "    print(\"hard voting:\\n\", report['hard'])\n",
    "     \n",
    "    \n",
    "    # save predictions ----------------------------------------------------\n",
    "    \n",
    "    DIR = 'results/' + _DATASET_ + '/' + _LANGUAGE_ + '/' + _PRED_DIR_ + '/' + str(_NUM_AUTHORS_) + '_authors/test_split_' + str(split + 1) + '/'\n",
    "    if not os.path.exists(DIR):\n",
    "        os.makedirs(DIR)\n",
    "\n",
    "    with open(DIR + 'predictions.pickle', 'wb') as f:\n",
    "        pickle.dump(author_predictions, f)\n",
    "\n",
    "    with open(DIR + 'report.txt', 'w') as f:\n",
    "        f.write(\"soft voting:\\n\" + report['soft'] + '\\n\\n')\n",
    "        f.write(\"hard voting:\\n\" + report['hard'])\n",
    "    \n",
    "    \n",
    "    # delete adapter -------------------------------------------------------\n",
    "    \n",
    "    model.delete_adapter(task)\n",
    "    model.delete_head(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "858952e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft results:  [0.7628855117275682, 0.7209803117309269, 0.7500482951801409, 0.6921945910901176, 0.7754454519160401]\n",
      "\n",
      "Hard results:  [0.7518696526570542, 0.7225423814178081, 0.7335837548185419, 0.67676603057959, 0.7682725540588443]\n",
      "\n",
      "\n",
      "Soft statistics: \n",
      "\t[avg, std]: [0.7403108323289588, 0.030092249911903783]\n",
      "\n",
      "Hard statistics: \n",
      "\t[avg, std]: [0.7306068747063678, 0.031124085499019058]\n"
     ]
    }
   ],
   "source": [
    "# report statistics\n",
    "\n",
    "print('Soft results: ', f1s_soft)\n",
    "print('\\nHard results: ', f1s_hard)\n",
    "\n",
    "f1s_soft = np.array(f1s_soft)\n",
    "f1s_hard = np.array(f1s_hard)\n",
    "\n",
    "FewShot_Results = {'soft': [f1s_soft.mean(), f1s_soft.std()], 'hard': [f1s_hard.mean(), f1s_hard.std()]}\n",
    "\n",
    "print('\\n\\nSoft statistics: ')\n",
    "print('\\t[avg, std]:', FewShot_Results['soft'])\n",
    "\n",
    "print('\\nHard statistics: ')\n",
    "print('\\t[avg, std]:', FewShot_Results['hard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea8ba5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e598acda",
   "metadata": {},
   "source": [
    "## Training with all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccc15e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading data...\n",
      "    Done\n",
      "Preprocessing text...\n",
      "    Done\n",
      "Tokenizing...\n",
      "    Done\n",
      "Merging data...\n",
      "    Done\n",
      "\n",
      "Total Instances: 2645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tools.DataLoaders import DatasetPAN\n",
    "\n",
    "baseTest.get_all_data(_TWEET_BATCH_SIZE_, tokenizer, _MAX_SEQ_LEN_, _PREPROCESS_TEXT_)\n",
    "\n",
    "Test  = DatasetPAN(baseTest , label_name)\n",
    "Train = DatasetPAN(baseTrain, label_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66c7ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "samples = 4 * _NUM_AUTHORS_ * int(100 / _TWEET_BATCH_SIZE_)\n",
    "_LOGGING_STEPS_ = int(samples / _BATCH_SIZE_)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate               = _LEARNING_RATE_,\n",
    "    num_train_epochs            = _EPOCHS_,\n",
    "    per_device_train_batch_size = _BATCH_SIZE_,\n",
    "    per_device_eval_batch_size  = 200,\n",
    "    logging_steps               = _LOGGING_STEPS_,\n",
    "    output_dir                  = _OUTPUT_DIR_,\n",
    "    save_total_limit            = 5,\n",
    "    overwrite_output_dir        = True,\n",
    "    remove_unused_columns       = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "340ae862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaAdapterModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaAdapterModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaAdapterModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/001/usuarios/isaac.bribiesca/anaconda3/envs/NLP/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2846\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 890\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='890' max='890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [890/890 02:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.680600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to checkPointsParallel/checkpoint-500\n",
      "Configuration saved in checkPointsParallel/checkpoint-500/age/adapter_config.json\n",
      "Module weights saved in checkPointsParallel/checkpoint-500/age/pytorch_adapter.bin\n",
      "Configuration saved in checkPointsParallel/checkpoint-500/age/head_config.json\n",
      "Module weights saved in checkPointsParallel/checkpoint-500/age/pytorch_model_head.bin\n",
      "Configuration saved in checkPointsParallel/checkpoint-500/age/head_config.json\n",
      "Module weights saved in checkPointsParallel/checkpoint-500/age/pytorch_model_head.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "***** Running Prediction *****\n",
      "  Num examples = 2645\n",
      "  Batch size = 200\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 142/142 [00:00<00:00, 2118.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoAdapterModel\n",
    "from tools.DataLoaders import DatasetCrossVal\n",
    "from transformers import AdapterTrainer\n",
    "from tools.Testing import compute_author_predictions\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import pickle\n",
    "\n",
    "# initialize base model\n",
    "\n",
    "model = AutoAdapterModel.from_pretrained(_PRETRAINED_LM_)\n",
    "\n",
    "\n",
    "# train\n",
    "\n",
    "task = label_name\n",
    "\n",
    "# add adapter --------------------------------------------------------\n",
    "\n",
    "model.add_adapter(adapter_name = task,config = _ADAPTER_CONFIG_)\n",
    "model.add_classification_head(head_name = task, num_labels = len(class_dict))\n",
    "\n",
    "model.set_active_adapters(task)\n",
    "model.train_adapter(task)\n",
    "\n",
    "\n",
    "# create trainer and train -------------------------------------------\n",
    "\n",
    "trainer = AdapterTrainer(\n",
    "    model           = model,\n",
    "    args            = training_args,\n",
    "    train_dataset   = Train,\n",
    ")\n",
    "trainer.args._n_gpu = _NO_GPUS_\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# get predictions ----------------------------------------------------\n",
    "\n",
    "results            = trainer.predict(Test)\n",
    "author_predictions = compute_author_predictions(baseTest, results.predictions, task, len(class_dict))\n",
    "\n",
    "\n",
    "# report metrics -----------------------------------------------------\n",
    "\n",
    "report = {'soft': classification_report(author_predictions['true'], author_predictions['pred_soft'], digits=4), \n",
    "           'hard': classification_report(author_predictions['true'], author_predictions['pred_hard'], digits=4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dc3b108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "\n",
      "soft voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9091    0.8929    0.9009        56\n",
      "           1     0.7324    0.8966    0.8062        58\n",
      "           2     0.7000    0.3500    0.4667        20\n",
      "           3     0.6667    0.5000    0.5714         8\n",
      "\n",
      "    accuracy                         0.7958       142\n",
      "   macro avg     0.7520    0.6599    0.6863       142\n",
      "weighted avg     0.7938    0.7958    0.7825       142\n",
      " \n",
      "\n",
      "hard voting:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9434    0.8929    0.9174        56\n",
      "           1     0.7361    0.9138    0.8154        58\n",
      "           2     0.7000    0.3500    0.4667        20\n",
      "           3     0.7143    0.6250    0.6667         8\n",
      "\n",
      "    accuracy                         0.8099       142\n",
      "   macro avg     0.7734    0.6954    0.7165       142\n",
      "weighted avg     0.8115    0.8099    0.7981       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Results:\\n\")\n",
    "print(\"soft voting:\\n\", report['soft'], '\\n')\n",
    "print(\"hard voting:\\n\", report['hard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d744c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
